#!/bin/sh
#if 0
# run.sh
# This script has been machine-generated by MOE.
#
# COPYRIGHT (C) 2020 CHEMICAL COMPUTING GROUP ULC ("CCG").
# ALL RIGHTS RESERVED.
#
# PERMISSION TO USE, COPY, MODIFY AND DISTRIBUTE THIS SOFTWARE IS HEREBY
# GRANTED PROVIDED THAT: (1) UNMODIFIED OR FUNCTIONALLY EQUIVALENT SOFTWARE
# DERIVED FROM THIS SOFTWARE MUST CONTAIN THIS NOTICE; (2) ALL CODE DERIVED
# FROM THIS SOFTWARE MUST ACKNOWLEDGE THE AUTHOR(S) AND INSTITUTION(S); (3)
# THE NAMES OF THE AUTHOR(S) AND INSTITUTION(S) NOT BE USED IN ADVERTISING
# OR PUBLICITY PERTAINING TO THIS SOFTWARE WITHOUT SPECIFIC WRITTEN PRIOR
# PERMISSION; (4) ALL CODE DERIVED FROM THIS SOFTWARE BE EXECUTED WITH THE
# MOLECULAR OPERATING ENVIRONMENT LICENSED FROM CCG.
#
# CCG DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING
# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, AND IN NO EVENT
# SHALL CCG BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR
# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER
# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

# Automatically generated on Tue Jun 15 12:36:09 2021
# MOE 2020.0901 (Chemical Computing Group)

# VERSION hpc_run.sh     48091.2020.11.1.23.48.7    $MOE/lib/sh
# VERSION hpc.svl        13001.2020.11.1.23.53.44   $MOE/svl/msys
# VERSION dock_u.svl     2088.2020.10.29.22.33.15   $MOE/svl/calc.svl



# (see PAYLOAD below for app-specific code)
# === PREAMBLE:==============================================================
#
# NOTE:  "-e" is needed to avoid reporing a job success in the presence of
# undetected code failures.
# NOTE: "-u" can be used to enforce code quality in the script preamble.
# However, it is more stringent than a typical payload code can handle:
# for safety, we "set +u" after the preamble.

set -a			# allexport: export all assigned vars
set -e			# errexit: exit on any errors
# set -u		# nounset: error if expanding non-existing var
# set -x		# DEBUGGING: SET_X
PS4='+ $LINENO '	# in case -x is used

# Note: If -tid k, execute task k (skip job control). If -submit, schedule
# and/or execute (sequentially) all tasks 1-N, honoring all job dependencies.
# Don't use $0: slurm/sge uses a renamed copy of run.sh in an ad-hoc dir.

# Note: this script consists of several steps:
#   STEP_1: COMMAND_LINE process cmd.line args
#   STEP_2: QTASK_ID, TASK_MODE: determine processing mode, $task_mode.
#   STEP_3: VALIDATE:
#   STEP_4: COMMANDS:
#   STEP_5: SUBMIT:  submit the job for execution
#   STEP_6: RESVARS: prepare resource spec env.vars used by payload preampble
#   STEP_7: PAYLOAD: portion of "run.sh" generated ad-hoc by each app

task_N=1	# #tasks (except the epilog)
task_N0=0	# last task# (0 if epilog)
task_JN=2	# #submission cmds (+1 if epilog)
task_parts=1	# #partitions for sngl.node graphs
task_max=0	# max.#concurrent jobs
task_name='MOE(Greg)(r9m9a8)E__onedrive - the university of memphis_guides_ligand_docking_tutorial_files_example_dock'
task_qsys='sh'
task_host=''	# remote host: 'ruser@rhost:rdir'
task_qname=''	# q.partition (4th col in hpc.cfg)
task_qid=''	# queue ID (1st col in hpc.cfg)
task_qargs_ddash=""
task_qargs_moe=""
task_qargs_sge=""
task_qargs_slurm=""
task_qargs_lsf=""
task_qargx_sge=""
task_qargx_slurm=""
task_qargx_lsf=""
task_id=		# non-empty: perform submission else 0-N
task_sh="$0"		# this script (including path)
task_shx="${0##*/}"	# this script's tailname (on Win, allow for bslashes)
[ -n "${WINDIR-}" ] && [ -z "${WINDIR##*\\*}" ] && task_shx="${0##*\\}"
task_jctl=		# job control
task_rdir=		# remote directory
task_qargs=		# default queue resource arguments (-qargs)
task_qargx=		# extra queue resource arguments (+qargs)
task_logmode=		# '',0,2=don't, 1=do use run.log, 2=stdout/err to CWD
task_submit=false	# submit mode
task_test=false		# test mode
verbose=false		# activates extra print statements
task_mode=

if [ -n "${testing-}" ]; then
    [ -n "${testing_TN-}" ] && task_N="$testing_TN"
    [ "${testing_qsys-unset}" != 'unset' ] && task_qsys="${testing_qsys:-}"
    [ "${testing_host-unset}" != 'unset' ] && task_host="${testing_host:-}"
fi

[ "${0%/*}" = "$0" ] && task_src=. || task_src="${0%/*}"
_ecode=; _elabel=				# error code reported by _err
_ppfx="${task_pid:+P}${task_pid=}"		# used by subjobs, e.g. "P0.1."
[ -n "${task_lastid-}" ] && _ppfx="P$task_pid${task_lastid}.1." # see PPFX

# _print_stack prints the current stack trace to stderr

_print_stack () {
    [ -z "${BASH-}" ] && return 0		# bash only

    _caller () { caller "$1" >&2 || { printf '\n' >&2; return 1; } }
    _c () { { printf '+ '; _caller "$1"; }	>&2; }

    printf '\n'					>&2
    command -v caller 2> /dev/null >&2 && _c 2 && _c 3 && _c 4 && _c 5 || true
    printf '\n'					>&2
}

# _cleanup is called by "trap" on INT,TERM,EXIT
# Note: exit N: 0=job success 1=job failure, 2=submit param/syntax error

_cleanup () {
    _ccode="$?"
    set +x			# turn off debugging trace (if is was on)

    local _tpfx _sfx _sfx2 _ff
    [ "$_ccode" = '0' ] && _sfx='_ok' || _sfx='_err'
    _tpfx=".${_ppfx=}T${task_id:-X}"			# "TX" if no task_id

    _sfx2=
    [ -z "${_ccode#[2345]}" ]	&& _sfx2="_err.${_elabel-}.${_ccode}"

	# Ensure a T0 marker in a finished run.  If epilog of if last task &
	# no epilog, set $_ff=true and add '.T0_ok' or '.T0_err' marker.

    if [ "${task_id-}" = '0' ]; then		_ff=true	# expl.epilog
    elif [ "${task_N0-0}" = '0' ]; then		_ff=false	# before last
    elif [ "${task_id:-X}" = "$task_N0" ]; then	_ff=true	# impl.epilog
    else					_ff=true	# non-epilog
    fi

	# Ensure end-of-task markers (if run.log is used):
	# Repl '.T<num>_start with '.T<num>_ok/_err' in _log_sdir & _log_last.

    if [ -n "${_log_sdir-}" ] && [ -d "$_log_sdir" -a -w "$_log_sdir" ]; then
	touch "${_log_sdir}/${_tpfx}${_sfx}"	# task done
	rm -f "${_log_sdir:?}/${_tpfx}"'_start'	# no longer running
	$_ff && touch "${_log_sdir}/.${_ppfx}T0${_sfx}"
	$_ff && rm -f "${_log_sdir}/.${_ppfx}T0_unk"
	[ -n "$_sfx2" ] && touch "${_log_sdir}/${_tpfx}${_sfx2}" # task error

	    # On failure, future-notify dependent tasks (with .E_k stubs)

	if [ "$_sfx" != '_err' ]; then :	# not a failure
	elif [ -z "${task_id-}" ]; then :	# subm.task: no dependency
	elif [ "$task_id" != '0' ]; then	_after_onfail "$task_id"
	elif [ "$task_parts" = '0' ]; then	_after_onfail "$task_N"
	else					_after_onfail "$task_parts"
	fi
    fi

	# End-of-task markers for $_log_last dir (=.jlast) as well.

    if [ -n "${_log_last-}" ] && [ -d "$_log_last" -a -w "$_log_last" ]; then
	touch "${_log_last}/${_tpfx}${_sfx}"	# task done
	rm -f "${_log_last:?}/${_tpfx}"'_start'	# no longer running
	$_ff && touch "${_log_last}/.${_ppfx}T0${_sfx}"
	$_ff && rm -f "${_log_last}/.${_ppfx}T0_unk"
	[ -n "$_sfx2" ] && touch "${_log_last}/${_tpfx}${_sfx2}" # task error
    fi

	# NOTE: SGE: magic exit codes; 99=reschedule 100=set Eqw state (zombie)

    if [ -z "${SGE_TASK_ID-}" ]; then :		# non-SGE
    elif [ "$_ccode" = '100' ]; then
	_ccode=1				# do NOT set Eqw
    elif [ "$_ccode" = '99' ]; then
	_ccode=1				# do NOT reschedule
    fi

	# Process success & errors from payload or elsewhere
	# Typical: exit 0 on success, exit 1 on failure
	# Rare: exit 2 on config err, unexpected errors, submit errors
	# Note: if submit error (w/o job log subdir), report to _err.txt
	# (since sub.task has no "T<k>.err", record info to "_err.txt")

    if [ "$_ccode" = '0' ]; then		# task finished with success
	return 0
    elif [ "$_ecode" = '0' ]; then		# payload error
	[ "$_ccode" = '2' ] && _err 2 "${_elabel-}" 'Startup failed'
    elif [ -z "$_ecode" ]; then			# unknown err before payload
	_print_stack
	_err 4 E_unk "Unexpected exit $_ccode"
    elif [ -d "${_log_last-}" -a -z "${task_id-}" ]; then # setup/submit task
	_x="$_log_last/_${_ppfx-}err.txt"	# in stead of stderr file
	_ivalxx	"$@"				>>  "$_x" # task params
	_print_stack				2>> "$_x" # stack trace
	printf '%s: exit %s %s\n' "$task_shx" "$_ecode" "${_elabel-}" >>  "$_x"

    fi

    exit $_ccode
}

trap '_cleanup' INT TERM EXIT

# _err <ecode> <elabel> <esg> is called on errors that are NOT simple job
# failures.  The function will print "emsg [elabel]" to stderr (not stdout)
# and exit with the given exit code, ecode.  If this is the setup task
# (i.e task_id=''), we also print the error message to _log_last/_err.txt
# Codes: 2=bad param 3=startup/config 4=bug  5=glitch (wrong assumptions)
# Codes NOT used with _err: 0=success 1=job failure
# Note: failed moe_init.sh etc should exit 2 [=bad init params] (not exit 3)

_err () {
    set +x			# turn off debugging trace (if is was on)
    _ecode=$1; shift; _elabel=$1; shift
    [ "${_ecode-}" = 0 ]	&& _err 5 E_err_0 "$*"	# safety: don't _err 0!
    [ -z "${_ecode#[345]}" ]	&& _ivalxx >&2 # print diagnostics

    printf '%s: %s [%s:%s]\n' "$task_shx" "$*" "${task_mode-}" "$_elabel" >&2
    if [ -n "${task_id-}" ]; then :	# compute task: print nothing
    elif [ -n "${_log_last-}" ]	&& [ -d "$_log_last" -a -w "$_log_last" ]; then
	_x="$_log_last/_${_ppfx-}err.txt"	# in stead of stderr file
	printf "%s: " "$task_shx"			>> "$_x"
	printf '%s ' "$*"				>> "$_x"
	printf '[%s:%s]\n' "${task_mode-}" "$_elabel"	>> "$_x"
	_print_stack					2>> "$_x"
    fi
    exit "$_ecode"
}

MOE_ERRFCN () { _err "$@"; }

# _unset_vars unsets script variables that are NOT meant to be exported
# to the compute task.
# Note: do NOT unset task_shost, task_N, task_parts, task_max, task_id, ...

_unset_vars () {
    unset task_submit task_jctl task_host task_qname task_qsys
    unset task_rdir task_sh task_src
    unset _qsysd _qtask_id _flow _val _sfx _host
}

# _usage prints help msg to stdout (-h, -help, --help)
# _pr prints an individual line of the help message

_prh () { printf "    %-24s %-21s %s\n" "$1" "$2" "${3-}"; }

_usage () {	#
    local _host

    _host="$task_host"		# task_host has now been stripped of dir by now
    if [ -n "$task_rdir" ]; then _host="$_host:$task_rdir"; fi	# append dir

    printf '%s [options] ...\n' "$task_shx"
    _prh '-help'		    'print help'
    _prh '-name name'		    'name of job'		"$task_name"
    _prh '-qsys {sh|slurm|sge|lsf}' 'pick job system'		"$task_qsys"
    _prh '-qname'		    'specify a queue'		"$task_qname"
    _prh '-qargs argstr'	    'replace job arguments'	"$task_qargs"
    _prh '+qargs argstr'	    'add job arguments'		"$task_qargx"
    _prh '-host [user@]host[:path]' 'remote host/headnode'	"$_host"
    if [ "$task_N" -eq 1 ]; then
	_prh '-parts no'	    'partition simple jobs'	"$task_parts"
	_prh '-max no'		    'max simultaneous jobs'	"$task_max"
    fi
    _prh "-logmode"	"1=logdir if qsys=SH"			"$task_logmode"

    _prh '-test'	'report actions'
    _prh '-submit'	'submit jobs'
    _prh '-status'	'status of jobs'
    _prh '-cancel'	'cancel jobs'
    _prh '-delete'	'delete host data'
    _prh '-upload'	'upload to host'
    _prh '-download'	'download from host'

    printf '\n'
}

_ival () {	# pretty-print input values
    printf '%-6s : %s\n' "-name"  "$task_name"
    printf '%-6s : %s\n' "-qsys"  "$task_qsys"
    printf '%-6s : %s\n' "-qname" "$task_qname"
    printf '%-6s : %s\n' "-qargs" "$task_qargs"
    printf '%-6s : %s\n' "+qargs" "$task_qargx"
    printf '%-6s : %s\n' "-host"  "$task_host""${task_rdir:+:}""${task_rdir-}"
}

# _ensure_vars ensures that all need task_xxx are defined (albeit empty)

_ensure_vars () {
    task_id="${task_id=}"
    task_host="${task_host=}"
    task_shost="${task_shost=}"
    task_name="${task_name=}"
    task_qid="${task_qid=}"
    task_qname="${task_qname=}"
    task_qsys="${task_qsys=}"
    task_qargs_moe="${task_qargs_moe=}"
    task_qargs_sge="${task_qargs_sge=}"
    task_qargs_slurm="${task_qargs_slurm=}"
    task_qargs_lsf="${task_qargs_lsf=}"
    task_qargx_sge="${task_qargx_sge=}"
    task_qargx_slurm="${task_qargx_slurm=}"
    task_qargx_lsf="${task_qargx_lsf=}"
    task_qargs="${task_qargs=}"
    task_qargx="${task_qargx=}"
    task_qargs_QSYS="${task_qargs_QSYS-}"
    task_N="${task_N=}"
    task_JN="${task_JN=}"
    task_N0="${task_N0=0}"
    task_parts="${task_parts=}"
    task_max="${task_max=}"
    task_logmode="${task_logmode=}"
}

# _ivalx prints submission values in the format of SH assignments.
# Note: task_qargs_QSYS is the "actual" arg given to the submit cmd.
# (Do NOT set explicitly, either as a default run.sh or from cmd.line!)

_ivalx () {
    _ensure_vars
    cat <<-EOF
	task_host='$task_host'
	task_shost="$task_shost"
	task_shx='${task_shx-}'

	task_name='$task_name'
	task_qid='$task_qid'
	task_qname='$task_qname'
	task_qsys='$task_qsys'
	task_qargs_moe='$task_qargs_moe'
	task_qargs_sge='$task_qargs_sge'
	task_qargs_slurm='$task_qargs_slurm'
	task_qargs_lsf='$task_qargs_lsf'
	task_qargx_sge='$task_qargx_sge'
	task_qargx_slurm='$task_qargx_slurm'
	task_qargx_lsf='$task_qargx_lsf'
	task_qargs='$task_qargs'
	task_qargx='$task_qargx'
	task_qargs_QSYS='${task_qargs_QSYS-}'
	task_qargs_ddash='${task_qargs_ddash-}'
	task_N='$task_N'
	task_JN='$task_JN'
	task_N0='${task_N0:-0}'
	task_parts='$task_parts'
	task_max='$task_max'
	task_logmode='$task_logmode'
	EOF
}

# _ivalxx is an extended version of _ivalx, useful for diagnostics of errors

_ivalxx () {
    echo '#'
    echo '# === IVALXX ================================='
    echo "# task_id='${task_id-}'"
    echo "# task_last='${task_last-}'"
    echo "# task_logdir='${task_logdir-}"
    echo "# _ppfx='${_ppfx-}'"
    echo '#'
    echo '# === IVALX: ================================='
    _ivalx
    cat <<-EOF
	#
	# === DIAG: ==================================
	# _jargv=${_jargv-}
	task_jctl='${task_jctl-}'
	task_lastid='${task_lastid-}'
	task_mode='${task_mode-}'
	task_pid='${task_pid-}'
	task_rdir='${task_rdir-}'
	task_sfn='${task_sfn-}"
	task_sh="${task_sh-}"
	task_shx='${task_shx-}'
	task_src='${task_src-}'
	task_submit='${task_submit-}"
	task_test='${task_test-}'
	verbose='${verbose-}'
	# _flow=${_flow-}
	#
	# === STATE: =================================
	# PWD='$PWD'
	_hostname='${_hostname-}'
	_implicit='${_implicit-}'
	_log_id='${_log_id-}'
	_log_dir='${_log_dir-}'
	_log_sdir='${_log_sdir-}'
	_log_last='${_log_last-}'
	_newSarg='${_newSarg-}'
	_qsysd='${_qsysd-}'
	_qtask_id='${_qtask_id-}'
	_rhost='${_rhost-}'
	_rsubid='${_rsubid-}'
	EOF
    [ $# -gt 0 ] && echo '# $@=' "$@"
    echo '# ============================================'
    echo ''
}

_debug () {		# _ivalx + a few extras useful for debugging
    _ivalx
    cat <<-EOF
	# Debug info:
	task_id=$task_id
	task_jctl=$task_jctl
	task_rdir=$task_rdir
	task_sh=$task_sh
	task_shx=$task_shx
	task_src=$task_src
	task_submit=$task_submit
	task_test=$task_test
	verbose==$verbose
	_flow=$_flow
	@="$@"
	EOF
}

# Check for internal flags: -tid, -name, -rsubid
# These are _NOT_ meant to be used by the top caller of run.sh (except -tid 1).
#  -tid     used by qsys=sh in the _seq fcn to advance & set task_id
#	    (others use qsys-specific vars, e.g. $SLURM_ARRAY_TASK_ID)
#  -name    used by all submitted tasks to set their $task_name value
#  -rsubid  allows re-submitted tasks to use the logdir of the caller

_last=; _rsubid=			# resubmit log info
for _word in "$@"; do
    if [ -z "$_last" ]; then		# check new attr
	case "$_word" in
	    -tid | -name | -rsubid) _last="$_word"	;;
	esac
	continue;
    fi

    if [ -n "${_word##[+-]*}" ]; then	# check/set value following an attr
	case "$_last" in
	    -tid)		task_id="$_word"	;;
	    -name)		task_name="$_word"	;;
	    -rsubid)		_rsubid="$_word"	;;
	esac
    fi
    _last=
done

# _reset_ppfx resets $_ppfx to a new, unique value, so that job state markers
# .T<xxx> of of this task do NOT clash with those of the current task or any
# future tasks. Note: This is needed only if this is a subtask of the main
# tasks, started either by a direct SH or by a resubmission.
# Note: The subtask is also indicated by a marker file, $_smarker.

_reset_ppfx () {
    local _pidx _pid_pfx _smarker

    # [ -z "${1-}" ]		&& _err 4 E_ppfx_1B 'Empty $1'
    [ -z "${_log_sdir}" ]	&& _err 4 E_ppfx_2B 'Empty $_log_sdir'
    [ -z "${_log_last}" ]	&& _err 4 E_ppfx_3B 'Empty $_log_last'
    [ ! -d "${_log_sdir}" ]	&& _err 3 E_ppfx_4 "$_log_sdir not a directory"
    [ ! -d "${_log_last}" ]	&& _err 3 E_ppfx_5 "$_log_last not a directory"

	# Set task_pid and ensure that it is unique.
	# Record the start of a subjob by the presence of the smarker file.

    _pid_pfx="${task_pid-}${1:-}${1:+.}"		# extend curr.pid
    _pidx=0						# try 1,2,3...
    while
	_pidx=$(( _pidx + 1 ))
	task_pid="${_pid_pfx}${_pidx}."			#$ e.g. "0.1."
	_ppfx="P${task_pid}"
	_smarker="${_log_sdir}/.${_ppfx}M_sjob"		# e.g. xxx/.P0.1.M_sjob
	[ -f "${_smarker}" ] && continue || break	# until not found
    do :; done
}

# _parse_rsubid sets logdir variables of a (resubmitted) subtask to those of
# the caller (compute) task. The $1 argument, is the value of -rsubid switch:
#	_rsubid="${_log_sdir}/.P{$task_pid-}T${task_lastid-0}"
#	... "<jobdir>/run.log/<_log_id>/.jstate/.P<task_pid>T<task_lastid>"
# Sets: $_log_dir, $_log_sdir, $_log_last, as well as $task_logdir, $_log_id.
# Sets $task_lastid and calls _reset_ppfx to set $task_pid, $_ppfx

_parse_rsubid () {
    # _rsubid="<jobdir>/run.log/$_log_id/.jstate/.P{$task_pid}T${task_lastid}
    # Caller sets: _rsubid="$_log_sdir/.P{$task_pid-}T${task_lastid:0}"
    _x="${_rsubid-}"
    [ -z "$_x" ]			&& _err 4 E_rsub_1B 'Empty $_rsubid'
    [ -n "${_x##*/.P*}" ]		&& _err 4 E_rsub_2B "Bad _rsubid $_x"

    # [ -n "${_x##*/.P*T[0-9]*}" ]	&& _err 4 E_rsub_2B "Bad _rsubid $_x"
    # task_lastid="${_x##*/.P*T}"		# =after "T"
    # [ -z "${task_lastid-}" ]		&& _err 4 E_rsub_2B "Bad _lastid $_x"

    task_pid="${_x##*/.P}";		 task_pid="${task_pid%%T*}"
    _log_sdir="${_x%*/*}"		# =before last "/" = ".../.jstate"
    [ -n "${_log_sdir##*/.jstate}" ]	&& _err 4 E_rsub_3B "Bad _log_sdir $_x"

    _x="${_log_sdir%/.jstate}"		# =before "/.jstate" = ".../<log_id>"
    _log_id="${_x##*/}"			# =after last "/" = <log_id>
    [ -n "${_log_id##20*}" ]		&& _err 4 E_rsub_4B "Bad _log_id $_x"

    _log_dir="$_x"			# =".../run.log/20*"
    task_logdir="$_x"			# same as $_log_dir (=do use run.log)
    _log_last="${_x%/*}/.jlast"		# =".../run.log/.jlast"
}

# _validate_log_dir is used by resubmission & compute tasks to verify the
# assumtions about state variables associated with run.log.

_validate_log_dir () {
    [ -z "${1-}" ]		&& _err 4 E_ldir_1B 'Empty $1'
    [ -z "${task_logdir-}" ]	&& _err 3 "$1"_xt2 '$task_logdir not set'
    [ ! -d "$task_logdir" ]	&& _err 3 "$1"_xd0 "$task_logdir not a directory"

    [ -z "${_log_dir-}" ]	&& _err 3 "$1"_xv1 '$_log_dir not set'
    [ -z "${_log_last-}" ]	&& _err 3 "$1"_xv2 '$_log_last not set'
    [ -z "${_log_id-}" ]	&& _err 3 "$1"_xv3 '$_log_id not set'
    [ -z "${_log_sdir-}" ]	&& _err 3 "$1"_xv4 '$_log_sdir not set'

    local _x
    _x="$_log_dir"
    [ "$_x" != "$task_logdir" ]	&& _err 3 "$1"_xc1 '$_log_dir != $task_logdir'
    _x="${_log_dir%%*$_log_id}"
    [ -n "$_x" ]		&& _err 3 "$1"_xc2 "_log_dir $_log_dir $_log_id"
    _x="$_log_dir"'/.jstate'
    [ "$_x" != "$_log_sdir" ]	&& _err 3 "$1"_xc3 "_log_sdir $_log_sdir $_x"
    _x="${_log_dir%%/$_log_id}/.jlast"
    [ "$_x" != "$_log_last" ]	&& _err 3 "$1"_xc4 "_log_last $_log_last $_x"

    [ ! -d "$_log_dir" ]	&& _err 3 "$1"_xd1 "$_log_dir not a directory"
    [ ! -d "$_log_sdir" ]	&& _err 3 "$1"_xd2 "$_log_sdir not a directory"
    [ ! -d "$_log_last" ]	&& _err 3 "$1"_xd3 "$_log_last not a directory"

    _x="$_log_last/_log_id"
    [ ! -f "$_x" ]		&& _err 3 "$1"_xi1 '$_log_id file missing'
    _x=$(cat "$_x" 2> /dev/null) || true		# last log id
    # DBG: uncomment this to cause an error (that should be properly caught)
    # _x=$(cat "_x")		# will cause error: file "_x" not found
    [ "$_x" != "$_log_id" ]	&& _err 3 "$1"_xi2 "_log_id file $_log_id $_x"

    return 0
}


# If resubmit task, set vars from -rsubid param sent by the caller.

if [ -n "${_rsubid-}" ]; then		# RSUBID
    _parse_rsubid "$_rsubid"		# set task_logdir etc
    _validate_log_dir 'E_rsubid'	# validate subdirs
    # _reset_ppfx "$task_lastid"	# reset & ensure unique
    _ppfx="P$task_pid"			# used by subjobs, e.g. "P0.1."
    touch "${_log_sdir}/.${_ppfx}M_rsub" "${_log_last}/.${_ppfx}M_rsub"
    task_lastid=

# If a subtask, ensure _ppfx unique.

elif [ -z "${_log_sdir}" ]; then :	# no run.log: do nothing
elif [ -n "${task_lastid-}" ]; then	# PPFX
    _reset_ppfx "$task_lastid"	# reset & ensure unique
    touch "${_log_sdir}/.${_ppfx}M_sjob" "${_log_last}/.${_ppfx}M_sjob"
fi

# _run executes "$@".  If $task_test, don't execute, only echo to stdout.

_run () { $task_test && echo "$@" || "$@"; }

# _quotes replaces every single quote, ', with 5 alternating quotes, '"'"'.
# This is to ensured that single-quoted items stay single quoted when
# transmitted to the remote in theform of _ssh/ssh arguments.

_quotes () { echo "$1" | sed -e "s/'/'\"'\"'/g"; }

# _flow_appendq appends "$1 $2" to "$_flow", if $2 is non-empty. If $2 contains
# sngl.quotes, each {'} will be replaced with {'"'"'}.  This ensures that when
# $_flow is given to _ssh, the remote /bin/sh will receive the correct value.
# Important: $_flow is always set with a sentinel SPC, i.e. "$_flow$1" is OK

_flow_appendq () {
    local _qflag _qval

    [ -z "$2" ] && return 0
    _qflag="$1"; _qval="$2"

    [ -z "${_qval##*"'"*}" ] && _qval="$(_quotes "$_qval")"	# quoted
    _flow="$_flow$_qflag '$_qval' "	# append "$1 $2" to $_flow
}

# _flow_appendq3 appends "$1 $2 $3" to "$_flow", if $3 is non-empty. If $3 has
# sngl.quotes, the fcn will requote them, similarly to the _floq_appendq above.

_flow_appendq3 () {
    [ -z "$3" ] && return 0
    _flow="$_flow$1 "; shift;		# append $1
    _flow_appendq "$@"			# append $2 $3
}

# _esc adds one extra escaping level to characters that need escaping prior to
# sending them over ssh.  The extra subshell and printf ensure that sed outputs
# are catenated with a space in between them (some version have a line ending)

_esc () {
    [ -z "$*" ] && return
    printf '%s ' "$(
	while true; do
	    printf "%s" "${1-}" | sed -e 's/[\$\* \(\)]/\\&/g'
	    if [ $# -gt 0 ]; then shift; fi
	    if [ -n "${1-}" ]; then printf " "; else return; fi
	done
    )"
}

# _ssh uses ssh to reach the set remote host, $task_host, and execute the
# given command, "$1", followed by the given parameters, "$@".
# Note: requote sngl.quotes in $@ in order to preserved them on the remote.

_ssh () {
    local _cmd
    _cmd="$1"; shift
    if $task_test; then echo ssh "$task_host" "$_cmd $(_esc "$@")"; fi
    ssh "$task_host" "$_cmd $(_esc "$@")"
}

# _subs apply multiple successive substitutions to an input string passed in
# as the first parameter

_subs () {
    local _out
    _out="${1-}"; shift
    while [ -n "${1-}" ]; do
	eval _out="\${_out$1}"; shift
    done
    printf '%s' "$_out"
}

# _read_mem accepts mem.size specification $1, $2 and returns, on stdout, that
# value in MB. The input extracted directly from QSYS. Exit 4 (=bug) on err.
#	$1	[""] input string that may include a suffix
#	$2	[""] default unit multiplier when no suffix is present

_read_mem () {
    local _mem _suffix

    if [ -z "$1" ]; then printf '0'; return; fi

    _mem="${1%B}"	# remove any suffix "B" to the memory string
    _suffix="${2%B}"	# remove any suffix "B" to the default units

    if [ "$((_mem))" -eq 0 ]; then printf '0'; return; fi

    if [ "$_mem" -eq "$_mem" ] 2>/dev/null; then true; else # _mem is not an int
	_x="${_mem%?}"					# drop the last char
	_suffix="${_mem#$_x}"
	_mem="$_x"
	unset _x
    fi

    if ! [ "$_mem" -eq "$_mem" ] 2>/dev/null; then	# not a number
	_err 4 E_rmem_1 "Illegal memory format: $1"	# wrong input format
    fi

    if   [ -z "$_suffix"    ]; then printf "%s" "$(( _mem / 1048576 ))"
    elif [ "$_suffix" = 'K' ]; then printf "%s" "$(( _mem / 1024 ))"
    elif [ "$_suffix" = 'M' ]; then printf "%s" "$_mem"
    elif [ "$_suffix" = 'G' ]; then printf "%s" "$(( _mem * 1024 ))"
    elif [ "$_suffix" = 'T' ]; then printf "%s" "$(( _mem * 1048576 ))"
    elif [ "$_suffix" = 'P' ]; then printf "%s" "$(( _mem * 1073741824 ))"
    elif [ "$_suffix" = 'E' ]; then printf "%s" "$(( _mem * 1099511627776 ))"
    else						# wrong suffix letter
	_err 4 E_rmem_2 "Unknown suffix letter: $_suffix (K|M|G|T|P|E)"
    fi

    return 0
}

# _numa takes a number of arguments, $1, an option name, $2 and the current
# list of args, $3-, and validates that the number of arguments is correct.
# Arguments are space separated.  A new option flag starts with "-" or "+"
#
#	$1  n[:m] n is the number of arguments required
#		  m are not validated for "-" or "+"
#	$2 is the current flag being processed
#	$3-* are the remaining arguments

_numa () {
    local _i _n _s _flag

    _n="${1-}"; _n="${_n%:*}"	# number of expected arguments (before ":")
    _flag="${2-}"		# name of the cmd.line switch/flag
    [ "$_n" -eq "$_n" ] 2>/dev/null || _err 4 E_numa0 "Not a number: $1"

    [ "$_n" != "$1" ] && _skip=${1#*:} || _skip=0	# don't validate those
    shift 2

    _i=0			# number of detected arguments
    while [ "$#" -gt 0 ]; do
	_s="${1#?}"		# all but the first char of the next word
	_s="${1%$_s}"		# extract the first char of the next word
	if [ "$_i" -ge "$_skip" ] && [ "$_s" = "-" ] || [ "$_s" = "+" ]; then
	    break
	fi

	_i=$((_i + 1))		# increment the valid argument counter
	shift
    done

    [ "$_i" -lt "$_n" ] && _err 2 E_numa1 "Missing argument for $_flag"
    [ "$_i" -gt "$_n" ] && _err 2 E_numa2 "Too many arguments for $_flag"
    return 0
}

# === STEP_1: process cmd.line args =========================================

# _set_jsub_names defines the set of task_xxx variables that define the queue
# submission parameters.  The function sets $_name to the list of those xxx's.

_set_jsub_names () {
    _names='host qsys qname qargs_moe'
    _names="$_names"' qargs_sge qargs_slurm qargs_lsf'
    _names="$_names"' qargx_sge qargx_slurm qargx_lsf'
}

# _jsub_to_task copies, for every xxx in $_names, $jsub_xxx to $task_xxx,
# provided that jsub_xxx is defined.  (Leave task_xxx as-is otherwise.)

_jsub_to_task () {
    local _sfx _names _var
    _set_jsub_names
    for _sfx in $_names; do
	eval _val='${'jsub_$_sfx'-NONE}'	# set to NONE if not defined
	[ "$_val" = 'NONE' ] && continue	# don't use if not defined
	eval task_$_sfx='${'jsub_$_sfx'}'	# copy jsub_xxx to task_xxx
    done
    return 0
}

# _task_to_jsub copies, for every xxx in $_names, $task_xxx to $jsub_xxx and
# sets task_xxx to empty, i.e. current task_xxx values will NOT be used.

_task_to_jsub () {
    local _sfx _names
    _set_jsub_names
    for _sfx in $_names; do
	eval jsub_$_sfx='${'task_$_sfx'-}'	# copy task_xxx to jsub_xxx
	eval task_$_sfx=			# set task_xxx to empty
    done
    return 0
}

# Scan ARGV for the presence of "-noimplicit", "-implicit".

_jargv=$(printf "\'%s\' " "$@")	# don't split multi-word items in $@
_newSarg=false		# presence of an explicitly given submit/jctl arg
_implicit=		# if empty, use task_xxx as-is
for flag in "$@"; do
    case "$flag" in
	--)		break		;;	# ignore argv after "--"
	-noimplicit)	_implicit=false	;;	# use empty task_xxx values
	-implicit)	_implicit=true	;;	# if jsub_xxx, copy to task_xxx
	-sh_x | -ssh_x)	eval "_${flag#-}=true" ;;
	-submit | -cancel | -status | -delete | \
	-upload | -ensure | -download | \
	-qsys | -qargs* | +qargs* )
			_newSarg=true	;;	# explicit submit/jctl args
    esac
done

"${_sh_x:-false}" && set -x

# If "-noimplicit", do NOT use task_xxx submission params.
# IF "-implicit" and jsub_xxxdefined, copy jsub_xxx to task_xxx & use them.

if [ -z "$_implicit" ]; then :		# use task_xxx values as-is
elif ! $_implicit; then	_task_to_jsub	# use empty task_xxx values
else			_jsub_to_task	# copy jsub_xxx (if any) to task_xxx
fi

# _newXxx will be set to "true" if -xxx is used in the loop below.

flag=""
_newHost=false
_newQueue=false
_newSys=false
_nameCwd=false
_qargsNewSfx=		# list of sfx's used in "-qargs_ sfx <val>"
_qargxNewSfx=		# list of sfx's used in "+qargs_ sfx <val>"
_upEnsure=false		# true=upload only if rmt.dir does NOT already exist

task_qargs=		# safety: start empty (do NOT default to non-empty)
task_qargx=

# COMMAND_LINE: Process cmd.line switches.

while [ -n "${1-}" ]; do
    flag="$1"; shift

    case "$flag" in

	# IMPORTANT: All cmd.lines args up to "--" will be stripped from "$@".
	# The remaining cmd.line will be given to each submitted job
	# (AFTER an explicit "--").

    --)		break;;			# stop processing flags

	# Tags below are _NOT_ meant to be used by the top caller of run.sh.
	# (Already processed above)

    -tid | -name | -rsubid)	_numa 1 "$flag" "$@";			shift;;

	# Action/control commands:

    -upload)	_numa 0 "$flag" "$@"; task_jctl='upload'		;;
    -ensure)	_numa 0 "$flag" "$@"; task_jctl='upload'; _upEnsure=true;;
    -download)	_numa 0 "$flag" "$@"; task_jctl='download'		;;
    -cancel)	_numa 0 "$flag" "$@"; task_jctl='cancel'		;;
    -status)	_numa 0 "$flag" "$@"; task_jctl='status'		;;
    -delete)	_numa 0 "$flag" "$@"; task_jctl='delete'		;;
    -submit)	_numa 0 "$flag" "$@"; task_submit=true			;;

	# Main qsys-specific submission switches

    -qargs)	_numa 1:1 "$flag" "$@"; task_qargs="$1";		shift;;
    +qargs)	_numa 1:1 "$flag" "$@"; task_qargx="$1";		shift;;
    -qargs_)	_numa 2:2 "$flag" "$@"; eval task_qargs_"$1"='$2'
		_qargsNewSfx="${_qargsNewSfx-} $1"; shift 2;;
    +qargs_)	_numa 2:2 "$flag" "$@"; eval task_qargx_"$1"='$2'
		_qargxNewSfx="${_qargxNewSfx-} $1"; shift 2;;

    -qsys)	_numa 1 "$flag" "$@"; task_qsys="$1";	_newSys=true;	shift;;
    -qname)	_numa 1 "$flag" "$@"; task_qname="$1";	_newQueue=true;	shift;;
    -addpatch)	_numa 1 "$flag" "$@"; _moe_addpatch="$1";		shift;;
    -addcustom)	_numa 1 "$flag" "$@"; _moe_addcustom="$1";		shift;;

	# Other run.sh-specific submission parameters

    -namecwd)	_numa 0 "$flag" "$@"; _nameCwd=true;;	# use task_name=CWD
    -qid)	_numa 1 "$flag" "$@"; task_qid="$1";	shift;; # info only
    -host)	_numa 1 "$flag" "$@"; task_host="$1";	_newHost=true;	shift;;
    -parts)	_numa 1 "$flag" "$@"; task_parts=$1;			shift;;
    -max)	_numa 1 "$flag" "$@"; task_max=$1;			shift;;

    -logmode)	_numa 1 "$flag" "$@"; task_logmode="$1";		shift;;
    -test)	_numa 0 "$flag" "$@"; task_test=true;;

	# Helper switches: print help, env.var values etc

    -h | -help | --help) _usage;	exit 0;;	# output help text
    -v | -verbose) _numa 0 "$flag" "$@"; verbose=true;;
    -ival)	_ival;			exit 0;;	# input values
    -ivalx)	_ivalx;			exit 0;;	# input in sh format
    -jargs)	_jargs;			exit 0;;	# defaults sh format
    -implicit | -noimplicit)		;;		# already handled
    -sh_x | -ssh_x)			;;		# already handled

    *)		_err 2 E_argv1 "unsupported option: $flag";;
    esac
done
unset flag

_ensure_vars		# ensure all needed vars are assigned

# If key parameters have changed, remove the default values.
# If -host, ignore default $task_qsys & $task_qname
# If -qsys, ignore default $task_host & &task_qname

if $_newHost; then				# explicit -host
    if ! $_newSys;   then task_qsys=""; fi	# unless explicit -qsyq
    if ! $_newQueue; then task_qname=""; fi	# unless explicit -qname
fi

if $_newSys; then				# explicit -qsys
    if ! $_newQueue; then task_qname=""; fi	# unless explicit -qname
    if ! $_newHost;  then task_host=""; fi	# unless explicit -host
fi

[ "${testing-}" = 'action' ] && _taction=true || _taction=false	# testing

# === STEP_2: determine processing mode, $task_mode =========================

# QTASK_ID: Detect qsys, $_qsysd, running this task: sh, slurm, sge, lsf
# detect QSYS ID, $_qtask_id, from a QSYS-specific env.var.

if   [ -n "${SLURM_ARRAY_TASK_ID-}" ];	then
    _qsysd='slurm'
    _qtask_id="$SLURM_ARRAY_TASK_ID"
elif [ -n "${SGE_TASK_ID-}" ];		then
    _qsysd='sge'
    _qtask_id="$SGE_TASK_ID"
elif [ -n "${LSB_JOBINDEX-}" ];		then
    _qsysd='lsf'
    _qtask_id="$LSB_JOBINDEX"
else
    _qsysd=
    _qtask_id=
fi


[ -z "${task_shost:=}" ] && _noshost=true || _noshost=false

_hostname="${HOSTNAME-}"
[ -z "${_hostname}" ] && _hostname="$(uname -n 2> /dev/null)"
[ -z "${_hostname}" ] && _err 3 E_host_1 'HOSTNAME/uname not found'

[ "${task_shost:=$_hostname}" = "$_hostname" ] \
    && _sremote=false || _sremote=true

# Detect remote:  _rhost=$task_host if remote; _rhost= if local (=this host)

_rhost="${task_host-}"
_rhost="${_rhost%:*}"			# strip :dir from task_host
if [ -z "$_rhost" ]; then				:	# empty=local
elif [ "$_rhost" = 'localhost' ]; then			_rhost=	# local
elif [ "${_rhost%%[.]*}" != "${_hostname%%[.]*}" ]; then :	# not this host
elif [ "$_rhost" = "$_hostname" ]; then			_rhost=	# same hostname
elif [ "$_rhost" = "${_rhost#*.}" ]; then		_rhost=	# no domain
elif [ "$_hostname" != "${_hostname#*.}" ]; then	:	# diff domain
else							_rhost=	# no domain
fi

# Determine the value of $task_mode.  Validate associated argv rules.
# Note: E_exe1 E_esh1 indicate bugs in the app-specific portion of run.sh.
# Note: 'Exe*Sub' indicates a subjob started from a compute task.

    # Non-SH compute tasks are _qsysd=slurm|sge|lsf

if [ -n "$_qsysd" ]; then		# non-SH compute task
    if ! $task_submit; then		task_mode='Exe'		# typical
    elif $_noshost; then	_err 4 E_exe1 'Submission host unspecified'
    elif $_sremote; then		task_mode='ExeRmtSub'	# rare
    else				task_mode='ExeSub'	# very rare
    fi

    [ -n "$task_jctl" ] &&	_err 2 E_exe2 "Unexpected -$task_jctl"

    # SH compute tasks are _qsys=, _task_id=K

elif [ -n "$task_id" ]; then		# SH compute task
    if ! $task_submit; then		task_mode='ExeSh'	# typical
    elif $_noshost; then	_err 4 E_esh1 'Submission host unspecified'
    elif $_sremote; then		task_mode='ExeShRmtSub'	# very rare
    else				task_mode='ExeShSub'	# rare
    fi
    $task_submit && task_logmode=${task_logmode:-1}	# default: use run.log

    [ -n "$task_jctl" ] &&	_err 2 E_esh2 "Unexpected -$task_jctl"

    # Job control tasks are task_jctl=CMD, e.g. "-cancel"

elif [ -n "$task_jctl" ]; then		# job control task
    if [ "$task_jctl" = 'upload' ] && ! $_upEnsure; then	# do upload
	! $task_submit &&		task_mode='Up' ||  task_mode='UpSub'
    elif [ "$task_jctl" = 'upload' ]; then			# up if needed
	! $task_submit &&		task_mode='Up2' ||  task_mode='Up2Sub'
    elif [ "$task_jctl" = 'download' ]; then			# do donwload
					task_mode='Down'
    elif [ -z "$_rhost" ]; then		task_mode='Jctl'	# local jctl
    else				task_mode='RmtJctl'	# remote jctl
    fi

    if [ -z "${task_mode%%Up*}" ]; then				# do upload
	[ -z "$task_host" ] &&	_err 2 E_up1 'Remote host unspecified'
	[ -z "$_rhost" ] &&	_err 2 E_up2 'Upload host is not remote'
    elif [ "$task_mode" = 'Down' ]; then			# do donwload
	$task_submit &&		_err 2 E_down1 "Unexpected -submit -$task_jctl"
	[ -z "$task_host" ] &&	_err 2 E_down2 'Remote host unspecified'
	[ -z "$_rhost" ] &&	_err 2 E_down3 'Download host is not remote'
    else							# other jctl
	$task_submit &&		_err 2 E_jctl1 "Unexpected -submit -$task_jctl"
    fi

    # Process SH submit/startup task.
    # If no explicit -logmode, then "-submit" implies -logmode 1 (=use run.log)
    # and no -submit implies -logmode 0 (=no run.log).
    # _SPECIAL_: Implicit SH submit/startup tasks: no explicit -submit
    # Note: if implicit submit, also upload if remote.
    # Note: if task explicit & uses run.log, it's SH subtasks will be the same

elif [ "${task_qsys:-sh}" = 'sh' ]; then # SH task
    if [ -n "${task_logmode-}" ]; then	:
    elif "$task_submit"; then		task_logmode=1	# explicit -submit
    elif [ -n "${_log_sdir-}" ]; then	task_logmode=1	# subtask of explicit
    else				task_logmode=0	# implicit SH submit
	[ -n "$_rhost" ] && { task_jctl='upload'; _upEnsure=true; }
    fi
    case "${task_logmode-}" in
	1 ) [ -z "$_rhost" ] &&	task_mode='ShSub'  || task_mode='ShRmtSub'  ;;
	2 ) [ -z "$_rhost" ] &&	task_mode='ShRun2' || task_mode='ShRmtRun2' ;;
	0 ) [ -z "$_rhost" ] &&	task_mode='ShRun'  || task_mode='ShRmtRun'  ;;
	* )	_err 2 E_logmode1 "Unexpected -logmode $task_logmode" ;;
    esac
    [ -z "${task_mode-}" ] &&	_err 4 E_nomode1B 'Unknown $task_mode'
    task_submit=true

    # Explicit submit tasks (explicit -submit) are task_submit=true.

elif $task_submit; then			# explicit -submit
    [ -z "$_rhost" ] &&			task_mode='Sub' || task_mode='RmtSub'
    [ "${task_qsys:-sh}" = 'sh' ] &&	task_mode="Sh$task_mode" # pfx "Sh"

    # _SPECIAL_: Implicit non-SH submit
    # If no explicit submit/jctl/qsys params & task_qsys _IS_ set in this file
    # (hardcoded), act implicitly, i.e. upload if remote & submit

elif ! $_newSarg && [ -n "${task_qsys-}" ]; then # qsys defined, no subm.args
    task_submit=true
    [ -z "$_rhost" ]	&&		task_mode='ImpSub' \
			||		task_mode='RmtImpSub'
    [ -n "$_rhost" ] && { task_jctl='upload'; _upEnsure=true; }

else
				_err 2 E_cmd0 'Missing command (e.g. -submit)'
fi
[ -z "${task_mode-}" ] &&	_err 4 E_nomode1B 'Unknown $task_mode'

[ -z "${task_logmode##*[012]*}" ] \
    || _err 2 E_logmode2 "Unexpected -logmode $task_logmode"

[ -z "${task_mode-}" ] &&	_err 4 E_nomode1B 'Unknown $task_mode'

# === STEP_3: ===============================================================
# VALIDATE: Validate & process the state of internal task_xxx variables

# Validate qsys.  The default system is sh.

case "${task_qsys:=sh}" in	# set to "sh" if empty
    slurm | sge | lsf | sh ) ;;
    *) _err 2 E_qsys1 "Unsupported value: -qsys $task_qsys (sh|slurm|sge|lsf)";;
esac

# Ensure that missing jobname OK only if local submit & -namecwd
# Note: If remote, jobdir is set $task_name (=jobname)

if [ -z "$task_name" ]; then
    [ -n "$task_host" ]	&& _err 2 E_tname1 'Missing task name'	# remote host
    [ -n "$task_jctl" ]	&& _err 2 E_tname2 'Missing task name'	# jctl cmd
    ! $_nameCwd		&& _err 2 E_tname3 'Missing task name'	# no -namecwd
fi

# Splitting a task in parts is only possible if task_N is 1.
# If task_parts unset, use task_parts=0.

if ! [ "${task_parts:=0}" -eq "$task_parts" ] 2>/dev/null; then	# non-numerical
    _err 2 E_tparts1 "Not a number: -parts $task_parts"
elif [ "$task_parts" -ne 0 -a $task_N -ne 1 ]; then
    _err 2 E_tparts2 "Unsupported: -parts $task_parts task_N=$task_N!=1"
fi

 _taction=false
if [ -n "${testing-}" ]; then
    case "$testing" in
	tmode )	  echo "$task_mode";		exit 0	;;
	tmodexx ) _ivalxx; echo "$task_mode";	exit 0	;;
	action)	  _taction=true				;;
	actionxx) _taction=true; _ivalxx		;;
	*)	_err 5 E_qsys1 "Bad value: \$testing=$testing" ;;
    esac
fi

unset _newHost _newSys _newQueue

if $verbose; then _usage; fi

# Extract the path to the job directory, task_rdir.
# If remote, set jobdir from $task_name (=jobname)

task_rdir="${task_host##*:}"			# dir component
[ "$task_rdir" = "$task_host" ] && task_rdir=.	# if no ":dir", use cwd
[ -n "$_rhost" ] && task_rdir="$task_rdir/$task_name";
task_host="$_rhost"				# host w/o :dir sfx

# Verify that $task_host is reachable and capable of running a POSIX SH.
# Set $_rsh to the name of that POSIX shell.

_rsh='/bin/sh'			# default: /bin/sh should mean "Shell"
_rsh_fn=			# name of $0 on the remote machine
if [ -n "$task_host" ] && ! $_taction; then	# remote & not testing
    _x=$task_test; task_test=false

    _rsh='/bin/sh'		# default: /bin/sh should mean "Shell"
    { printf '( set -o > /dev/null) || exit 1\n' | _ssh "$_rsh";
    } 2>/dev/null || _rsh=


    if [ -z "$_rsh" ]; then	# second attempt: an explicit "bash"
	_rsh='/bin/bash'
	{ printf '( set -o > /dev/null) || exit 1\n' | _ssh '/bin/bash';
	} 2>/dev/null || _rsh=
    fi

    if [ -z "$_rsh" ]; then	# report error (bad sh vs bad host)
	{ printf '( echo 123 > /dev/null) || exit 1\n' | _ssh '/bin/sh';
	} 2>/dev/null \
	&&	_err 3 E_rsh_1 "Posix SHELL not found: $task_host" \
	||	_err 3 E_rsh_2 "Host not reachable: $task_host"
    fi

    task_test="$_x"
fi

# _set_rsh_fn verifies this runfile's existence on a the remote (_ssh) host
# and sets $_rsh_fn to that pathname (valid on the remote host).
#
# Note: compute node uses a renamed copy of this file in an ad-hoc dir.
# - $_rsh_fn	... path to this script on the remote host
# - $task_sfn	... if subtask, $0 of the submission task
# Note: Only if -submit, -cancel, -delete, NOT if -upload, -download!

_set_rsh_fn () {
    _rsh_fn=$(				# result of the remote test
	cat <<-EOF | _ssh "$_rsh"		# test [ -f fn ] remotely
	    _x='${task_sh}'			# this file's full path
	    [ -f "\$_x" ]		&& { printf '%s' "\$_x"; exit 0; }

	    if [ -n '${task_sfn-}' ]; then	# compute task
		_x='${task_sfn%/*}/${task_shx}'
		[ -f "\$_x" ]	&& { printf '%s' "\$_x"; exit 0; }
	    else				# non-compute task
		_x='$task_rdir/${task_shx}'	# rdir + this file's tailname
		[ -z "\${_x##./*}" ] && _x="\$HOME/\${_x#./}"
		[ -f "\$_x" ]	&& { printf '%s' "\$_x"; exit 0; }
	    fi

	    printf 'TEST %s' "\$_x"		# "TEST " prefix compulsory
	    exit 0
	EOF
    )

    if [ -z "$_rsh_fn" ]; then		# _ssh failed
	_err 3 "$1"_xf1 "Failed to reach $task_host:$task_rdir/$task_shx"
    elif [ -z "${_rsh_fn##TEST *}" ]; then	# no $0 eqiv. on remote
	_err 3 "$1"_xf2 "Remote file $task_host:${_rsh_fn#TEST } not found"
    fi
}

# If this is a compute task (of an already submitted job), set its task id.
# Note: non-SH qsys should NOT set task_id (-tid); it will be detected

if [ -n "$task_id" ];			then :	# explicit task_id: leave as-is
elif  $task_submit;			then :	# submit task:	task_id=empty
elif [ -n "$task_jctl" ];		then :	# jctl task:	task_id=empty
else
    task_id="$_qtask_id"	# use ID detected from QSYS, empty if SH
fi

# Capture the flow-through options.

_flow=
if [ -n "$task_host" ]; then
    _flow="-name \"$task_name\" -host \"localhost\" "
    $task_test		&& _flow="$_flow-test "
    $task_submit	&& _flow="$_flow-submit "
    $verbose		&& _flow="$_flow-v "
    [ -n "$task_qsys" ]	&& _flow="$_flow-qsys \"$task_qsys\" "
    [ -n "$task_qname" ] && _flow="$_flow-qname \"$task_qname\" "
    [ -n "$task_qid" ] && _flow="$_flow-qid \"$task_qid\" "
    "${_ssh_x:-false}" && _flow="$_flow-sh_x "

    if $task_submit; then
	[ $task_parts -gt 0 ]	&& _flow="$_flow-parts \"$task_parts\" "
	[ -n "$task_max" ]	&& _flow="$_flow-max \"$task_max\" "
	[ -n "$_moe_addpatch" ]	&& _flow="$_flow-addpatch \"$_moe_addpatch\" "
	_val="$_moe_addcustom"
	[ -n "$_val" ]		&& _flow="$_flow-addcustom \"$_val\" "

	_flow_appendq '-qargs' "$task_qargs"	# -qargs val
	_flow_appendq '+qargs' "$task_qargx"	# -qargs val

	_val=					# safety
	for _sfx in $_qargsNewSfx; do		# -qargs_ sfx val
	    eval _val='$task_qargs_'"$_sfx"
	    _flow_appendq3 '-flow-qargs_' "$_sfx" "$_val"
	done
	for _sfx in $_qargxNewSfx; do		# -qargx_ sfx val
	    eval _val='"${task_qargx_'"$_sfx"'-}"'
	    _flow_appendq3 '-flow+qargs_' "$_sfx" "$_val"
	done
    fi
fi

# === STEP_4: ===============================================================
# COMMANDS: Process job control commands

# _sh_cancel kills all SH jobs associated with qsys=sh submission of $task_name.
# Note: if the job is running & the kill cmd was issued, set _did_act=true

_sh_cancel () {
    # external: _did_act task_name
    local _pslist _pgid _pgids _pids

    _pslist=$(			# -u <current user>, not MOE user!
	ps -u "${USER:-$LOGNAME}" -o pgid,pid,args 2>/dev/null \
	| grep -- '[M]OE' \
	| grep -- "$task_name" \
	| grep -- '-name' \
    ) || _pslist=

    [ -z "$_pslist" ] && return 0

    _pgids=$(			# extract group leader(s)
	printf '%s\n' "$_pslist" \
	| awk '{ printf("-%s ", $1); }'	# neg. group leaders
    ) || _pgids=
    [ -z "$_pgids" ]	&& return 0

	# Kill with pgid's; must be dash-prefixed; -TERM must be first 

    kill -TERM $_pgids > /dev/null 2>&1 && _did_act=true

	# Safety: verify that the job has been terminated

    _pslist=$(			# safety: check that jobs killed
	ps -u "${USER:-$LOGNAME}" -o pgid,pid,args 2>/dev/null
    ) || _pslist=
    [ -z "$_pslist" ] && return 0

	# Safety: if not killed w/ pgid, kill with pid

    for _pgid in $_pgids; do	# for each pgid
	_pgid="${_pgid#-}"	# remove leading dash
	_pids=$(		# safety: kill using pid, not pgid
	    printf '%s\n' "$_pslist" \
	    | awk '{ if ($1 == '"${_pgid:-0}"') print $2 }'
	) ||	_pids=
	[ -z "$_pids" ]	&& continue
	kill -TERM $_pids > /dev/null 2>&1 || true
    done
    return 0
}

# _cancel stops all jobs (of any qsys) of the name $task_name.
# If the job is running & the cancel cmd is issued, set _did_act=true

_cancel () {
    # external: _did_act task_name
    local _x

    (squeue -V > /dev/null 2>&1) && {		# check SLURM 
	_x=$(squeue -h -n "$task_name" 2>/dev/null) || _x=
	[ -n "$_x" ] && _did_act=true
	$_did_act && { _run scancel -n "$task_name" 2>/dev/null || true; }
    }

    (qdel -help     > /dev/null 2>&1) && {	# check SGE
	_x=$(qstat -j "$task_name" 2>/dev/null) || _x=
	[ -n "$_x" ] && _did_act=true
	$_did_act && { _run qdel "$task_name" 2>/dev/null || true; }
    }

    (bjobs -V       > /dev/null 2>&1) && {	# check LSF
	_x=$(bjobs -j "$task_name" 2>/dev/null) || _x=
	[ -n "$_x" ] && _did_act=true
	$_did_act && { _run bkill -J "$task_name" 0 2>/dev/null || true; }
    }

    _sh_cancel					# check & cancel SH
    return 0
}

# If task_id is non-empty, ensure that it is valid, i.e. 1..task_N.
# Renumber the last, cleanup task to task_id=0.
# Note: error indicates a payload bug with exit code "2" (not "4")

if [ -n "$task_id" ]; then
    [ $task_parts -ne 0 ] && _n=$task_parts || _n=$task_N
    if	 [ $((task_id == _n + 1)) -ne 0 ]; then		# epilot
	task_id=0
    elif [ $((task_id <  1     )) -ne 0 ]; then		# bug: task negative
	_err 2 E_tid1B "(task_id=$task_id) < 1"
    elif [ $((task_id <  _n + 1)) -ne 0 ];	then
	true
    elif [ $task_parts -ne 0 ];			then
	_err 2 E_tid2B "(task_id=$task_id) > (task_parts=$_n)+1"
    else
	_err 2 E_tid3B "(task_id=$task_id) > (task_N=$_n)+1"
    fi
    unset _n

# Process job control commands, if any (e.g. -cancel).
# Note: task_id will be empty.
# Note: "-upload" allows an additional "-submit".  If so, it will NOT exit
#   after the action and will continue to the (remoted) submission.
#   All other $task_jctl commands do NOT allow "-submit" and will complain is
#   "-submit" is present.  They will also exit immediately after the action.

elif [ -n "$task_jctl" ]; then
    if [ "$task_jctl" = 'upload' ]; then
	[ -z "$task_host" ] && _err 4 E_up1B 'No remote host'	# bug

	if ! $_upEnsure; then :				# upload
	elif $_taction; then  :				# testing only
	    _upEnsure=false				# pretend uploaded
	elif _ssh "$_rsh -c '[ ! -d \"$task_rdir\" ]'"; then
	    _upEnsure=false				# not found: upload
	else						# chk rdir contents
	    _x1=$(ls -opA "$task_src" | awk \
		'{ if (substr($0,length) != "/") printf("%s ",$4); \
		for (i=8;i<=NF;i++) printf("%s ",$i); \
		printf(":\n"); }' | sort) # WARNING: for now, top-level only
	    _x2=$(_ssh "ls -opA \"$task_rdir\"" | awk \
		'{ if (substr($0,length) != "/") printf("%s ",$4); \
		for (i=8;i<=NF;i++) printf("%s ",$i);  \
		printf(":\n"); }' | sort)
	    [ "$_x1" = "$_x2" ] || _upEnsure=false	# upload if diff
	    unset _x1 _x2
	fi

	if $_upEnsure; then				# same contents
	    $task_test && echo 'Destination exists: no upload'
	elif $task_test ; then
	    printf 'tar -C "%s" -czf - . | ' "$task_src"
	    printf 'ssh "%s" ... \\ \n' "$task_host"
	    printf '... tar -C "%s" -xzomf - ... \n' "$task_rdir"
	elif $_taction; then				# testing
	    $task_submit || { echo 'A_Upload'; exit 0; }
	else
	    tar -C "$task_src" -czf - . | \
	    _ssh "mkdir -p \"$task_rdir\" && \
		chmod +rwx \"$task_rdir\"; \
		tar -C \"$task_rdir\" -xzomf - && \
		chmod -R +rwX \"$task_rdir\"" || \
	    _err 2 E_upx_1 "Failed upload ${task_host}:${task_rdir}"
	fi
	$task_submit || exit 0		# if not -submit, exit now

	# All the other job controls cannot be used with -submit
	# 1) if $0=run.sh, copy rmt/jobdir/* to CWD/*
	# 2) if $0=*/run.sh, copy rmt/jobdir/* to CWD/jobdir/*

    elif $task_submit; then
	_err 4 E_jctl1B "Unexpected -submit -$task_jctl"

    elif [ "$task_jctl" = 'download' ]; then
	[ -z "$task_host" ] &&	_err 4 E_down2B 'Remote host unspecified'

	if $task_test ; then taropt='-tzf'; else taropt='-xvzmof'; fi
	_x=
	if [ "${0##*/}" = "$0" ]; then
	    $_taction && { echo 'A_DownloadIsDir'; exit 0; }	# testing
	    _ssh "tar -czf - -C \"$task_rdir\" ." | tar "$taropt" - || \
	    _x=E_downx_2
	else
	    $_taction && { echo 'A_DownloadMkDir'; exit 0; }	# testing
	    ( mkdir "$task_name"; cd "$task_name"
	    _ssh "tar -czf - -C \"$task_rdir\" ." | tar "$taropt" - ) || \
	    _x=E_downx_3
	fi

	if [ -z "$_x" ]; then :			# download OK
	elif ! ssh "$task_host" "$_rsh"  -c '"echo OK"' 2>/dev/null >&2; then
	    _err 2 E_downx_1 "Failed ssh $task_host"	# ssh can't connect
	else
	    _err 2 "$_x" "Failed download ${task_host}:${task_rdir}"
	fi

	# If task_host is not empty, call the remaining job control actions
	# from the host.

    elif [ -n "$task_host" ]; then
	$_taction && { echo "A_RmtJctl_$task_jctl"; exit 0; }	# testing
	_set_rsh_fn E_rfn1		# set _rsh_fn to a valid remote file
	if _ssh "$_rsh \"$_rsh_fn\" -$task_jctl $_flow" -- "$@"; then :
	elif ! ssh "$task_host" "$_rsh"  -c '"echo OK"' 2>/dev/null >&2; then
	    _err 2 E_ssh_2 "Failed ssh $task_host"	# ssh can't connect
	else
	    _err 2 E_ssh_1 "Failed ssh $task_host $_rsh_fn -$task_jctl"
	fi

	# The following actions are necessarily called from host.

    elif [ "$task_jctl" = 'delete' ]; then
	$_taction && { echo 'A_Jctl_delete'; exit 0; }	# testing
	_cancel
	if [ "${task_sh##*/}" != "${task_sh}" ]; then	# contains slashes
	    $task_test && { echo "(rm -rf '${task_sh%/*}') &";
	    } || {		  (rm -rf "${task_sh%/*}") & }	# bg process
	fi

	# On 'cancel', on all systems, find out whether the job is active.
	# If so, cancel it and record the action with a stub file.

    elif [ "$task_jctl" = 'cancel' ]; then
	$_taction && { echo 'A_Jctl_cancel'; exit 0; }	# testing
	_did_act=false
	_cancel			# sets _did_act=true if job exists (& killed)
	if $_did_act; then				# cancel cmd issued
	    if [ "${task_sh##*/}" != "${task_sh}" ]; then # contains slashes
		_log_last="${task_sh%/*}"'/run.log/.jlast'
	    fi
	    if [ -d "$_log_last" ]; then
		touch "$_log_last"'/.TX_stop' >/dev/null 2>&1 || true
		_log_id="$_log_last/.jlast"
		[ -f "$_log_id" ] && _log_id="$(cat $_log_id)" || _log_id=

		_log_sdir="${_log_last%/*}"'/'"$_log_id"'/.jstate'
		if [ -n "$_log_id" -a -d "$_log_sdir" ]; then
		    touch "$_log_sdir"'/.TX_stop' >/dev/null 2>&1 || true
		fi
	    fi
	fi

	# On 'status', report status on all systems.  Additionally, report
	# the summary of the state stub files.

    elif [ "$task_jctl" = 'status' ]; then
	$_taction && { echo 'A_Jctl_status'; exit 0; }	# testing
	(squeue --help > /dev/null 2>&1) && \
	    _run squeue -h -n "$task_name" 2>/dev/null || true
	(qstat -help   > /dev/null 2>&1) && \
	    _run qstat -j "$task_name" 2>/dev/null || true
	(bjobs -V      > /dev/null 2>&1) && \
	    _run bjobs -j "$task_name" 2>/dev/null || true

	    # Examine & report state of the last run

	printf '================================================\n'
	if [ "${task_sh##*/}" != "${task_sh}" ]; then # contains slashes
	    _dn="${task_sh%/*}"'/run.log/.jlast'
	else
	    _dn='run.log/.jlast'
	fi
	if [ ! -d "$_dn" ]; then
	    printf 'Job did not record status in run.log\n'
	elif [ ! -f "$_dn/_log_id" ]; then
	    printf 'Job did not record the submission\n'
	else
	    _x=$(cat "$_dn/_log_id" 2> /dev/null) || true
	    [ -n "$_x" ] && {
		printf 'Submission stamp : %s\n' "$_x"
		printf 'System type      : %s\n' "${_x##*_}"
	    }

	    _x=$(cat "$_dn/_task_qid" 2> /dev/null) || true
	    [ -n "$_x" ] && \
		printf 'Job queue ID     : %s\n' "$_x"

	    [ ! -f "$_dn/.TX_submit" ] && \
		printf 'Job submission was not recorded.\n'
	    [ -f "$_dn/.TX_stop" ] && \
		printf 'Job was canceled.\n'

	    if ! ls "$_dn"/.*T0_* 2>/dev/null >&2; then		# safety
		printf 'Status           : unknown\n'
		printf 'No task status has been recorded.\n'
	    elif ls "$_dn"/.*T0_unk 2>/dev/null >&2; then	# some _unk
		printf 'Status           : unfinished\n'
		printf 'Some tasks appear to be unfinished.\n'
	    elif ls "$_dn"/.*T0_err 2>/dev/null >&2; then	# some ERR
		printf 'Status           : failed\n'
		printf 'Some tasks have finished with errors.\n'
	    elif ls "$_dn"/.*T0_ok 2>/dev/null >&2; then	# all OK
		printf 'Status           : success\n'
		printf 'All tasks have finished with success.\n'
	    else						# safety
		printf 'Status           : unknown\n'
		printf 'Unexpected task status markers.\n'	# BUG
		ls "$_dn"/.*T0_* 2>/dev/null >&2 | head -5	# diag
	    fi

	    if ls "$_dn"/_*err.txt 2>/dev/null >&2; then
		printf 'Startup errors were detected.\n'
		tail -n 1 "$_dn"/_*err.txt 2>/dev/null
	    fi
	fi
	printf '================================================\n'
    fi

    [ "$task_jctl" = 'upload' ] || exit 0	# if not 'upload' exit now
fi

# === STEP_5: ===============================================================
# SUBMIT: Process job submission

# _after ensures that .A_k stores task_id's that depend on task_id=k
# Note: each task in _jlist=$1 depends on each task in _par=$2.
# All j's from _jlist are written in & appended to every .A_k, k from _par.

_after () {		# emitted by hpc_Script into run.sh
    [ -n "${_log_sdir-}" -a -d "$_log_sdir" -a -w "$_log_sdir" ] || return 0
    [ -n "${_log_last-}" -a -d "$_log_last" -a -w "$_log_last" ] || return 0
    [ -z "${1-}" -o -z "${2-}" ] && return 0		# no dependencies

    local _j _k _jlist _par _x
    _jlist="$1"		# each j in _jlist runs after any k in _par
    _par="$2"		# each k in _par notifies every j in _jlist on failure

	# .A_k stores all j's that depend on k

    for _k in $_par; do
	_x=".${_ppfx}A_${_k}"				# record dependencies
	echo $_jlist >> "${_log_sdir}/$_x"
	echo $_jlist >> "${_log_last}/$_x"
    done
    return 0
}

# _after_onfail creates .E_j for every j stored in file .A_k, k=$1, i.e.
# for every task_id=j that depends on task_id=k.  The existence of .E_j is
# then by _after_verify to exit 1 from tasks that depend on $1.

_after_onfail () {	# called from _clanup on exit 1
    [ -n "${_log_sdir-}" -a -d "$_log_sdir" -a -w "$_log_sdir" ] || return 0
    [ -n "${_log_last-}" -a -d "$_log_last" -a -w "$_log_last" ] || return 0

    local _fn _j _x
    _fn="${_log_sdir}/.${_ppfx}A_${1-}"			# recorded dependencies
    [ ! -f  "$_fn" ] && return 0			# no dependencies

    for _j in $(cat "$_fn"); do
	_x=".${_ppfx}E_${_j}"
	touch "${_log_sdir}/$_x" "${_log_last}/$_x"	# record failure
    done
    return 0
}

# _after_verify will do nothing if previous tasks (on which this task, $1,
# depends) were successful, but exit 1 otherwise.  Note: This (failure)
# condition for this task, task_id=j=$1, is indicated by the presence of file
# ".E_j": it indicates that j is meant to run _after_ some task task_id=k, but
# that task failed and created (or touched) ".E_j".

_after_verify () {	# called on submission
    [ -z "${_log_sdir:-}" ] && return 0			# safety: no run.log
    [ ! -f "${_log_sdir}/.${_ppfx}E_${1-}" ] && return 0 # no failure recorded
    _ecode=1		# This is an intentional exit 1, not E_unk
    exit 1						# parent task failed
}

# _chk_dir is used by the non-SH submit routines, _slurm, _sge, _lsf, to verify
# existence of the log directories expected & needed to record the submission.

_chk_dir () {
    [ -z "${1-}" ]		&& _err 4 E_sdir_1B 'Empty $1'
    [ ! -d "${_log_dir-}" ]	&& _err 3 ${1}_1 "$_log_dir not found"
    [ ! -d "${_log_sdir-}" ]	&& _err 3 ${1}_2 "$_log_sdir not found"
    [ ! -d "${_log_last-}" ]	&& _err 3 ${1}_3 "$_log_last not found"
    return 0
}

# _get_lsf_unit gets the unit letter for the LSF limits

_get_lsf_unit () {
    local _unit

    if [ -z "$LSF_ENVDIR" ]; then		echo "K"; return; fi
    if [ ! -f "$LSF_ENVDIR/lsf.conf" ]; then	echo "K"; return; fi

	# Grab the unit for limits from the configuration.

    _unit="$(grep "LSF_UNIT_FOR_LIMITS=" "$LSF_ENVDIR/lsf.conf")"

    if [ -z "$_unit" ]; then			# undefined unit for limits
	_unit="K";				# LSF default multiplier
    else
	_unit="${_unit#LSF_UNIT_FOR_LIMITS=}"	# remove the assignment preamble
	_unit="${_unit%B}"			# remove trailing B if any
    fi
    echo "$_unit"
}


# _get_lsf_scale scales the value of relevant LSF resources by a multiplier

_get_lsf_scale () {
    local _unit
    _unit="$(_get_lsf_unit)"
    case "$_unit" in
    K)	echo "1";;
    M)	echo "1000";;
    G)	echo "1000000";;
    T)	echo "1000000000";;
    P)	echo "1000000000000";;
    E)	echo "1000000000000000";;
    Z)	echo "1000000000000000000";;
    esac
    return
}

# _seg iteratively runs (SH) this script for each task in the given list, $2,
# setting $task_id with -tid to a higher number in each subseqent run.
# !!! naming & location of log/stdout/stderr files not yet settled

_seq () {
    local _var _tlist _log _rng _high _x

    local _can_bg=true
    if [ "${1-}" = 'SUBMIT' ]; then		# run wait for dependency
	_can_bg=false
	shift;

	if [ -n "$3" ]; then			# dependencies specified
	    _dep=$(echo "$3" | tr ':' ' ')	# space-separated dependecies
	     while [ -n "$(ps h $_dep)" ]; do sleep 2; done
	    unset _dep
	fi
    fi

    _argv=$(printf "\'%s\' " "$@")	# don't split multi-word items in $@
    _var="$1"; _rng=""; _high=""
    _tlist=${2%\%*}					# everything before "%"

	# Launch in the background

    if $_can_bg && ! [ "$task_mode" = "${task_mode#Sh*Sub}" ]; then
	nohup sh -c "_seq SUBMIT $_argv" > /dev/null 2> /dev/null < /dev/null &
	_job=$!				# pid of the bg process
	disown
	eval "$_var"="$_job"		# save the job id
	return 0
    fi
    shift 4

	# If run.log used, record submission.
	# Note: "_0" corresponds to "_${_job}" in slurm, sge, ...

    [ -n "${_log_dir-}" ] && \
	[ ! -d "${_log_dir}" ]	&& _err 3 E_seq_1 "$_log_dir not found"
    [ -n "${_log_sdir-}" ] && \
	[ ! -d "${_log_sdir}" ]	&& _err 3 E_seq_2 "$_log_sdir not found"

    _x=".${_ppfx}${_var}_0"		# i.e. ".${_ppfx}${_var}_${_job}"
    [ -n "${_log_sdir-}" ] && touch "${_log_sdir}/$_x"
    [ -n "${_log_last-}" ] && touch "${_log_last}/$_x"

	# Run (now, on this host) SH job of name $task_name
	# WARNING: the fcn returns _only_ after the job is finished

    while [ -n "$_tlist" ]; do
	_rng=${_tlist%%,*}; _tlist=${_tlist#*,}
	[ "$_rng" = "$_tlist" ] && _tlist=""
	_high=${_rng#*-}; _rng=${_rng%-*}
	_rng=$((_rng - 1))
	while [ "$_rng" -ne "$_high" ]; do
	    _rng=$((_rng + 1))
	    [ -n "${_log_dir-}" ] && {
		_log="${_log_dir}/${_ppfx}T${_rng}"
		_run sh "$task_sh" -name "$task_name" -tid $_rng "$@" \
		> "$_log".out 2> "$_log".err
	    } || {
		_run sh "$task_sh" -name "$task_name" -tid $_rng "$@"
	    }
	done
    done
    return 0
}

# _slurm submits (sbatch) to SLURM a new task w/ given dependencies, $3(%$2),
# and resources, $4, and stores the job id in "$1".
# Note: $2="n%s" means "run n tasks, but at most only s at the same time"

_slurm () {
    local _var _tlist _log _dep _job _res _queue _max _x
    _chk_dir 'E_slurm'

    _var="$1"
    _max="${2##*%}"					# everything after "%"
    _tlist="${2%\%*}"					# everything before "%"
    _res="$4"

	# process maximum concurent jobs in array

    [ -n "$_max" ] && [ ! "$_max" = "$2" ] && [ $_max -gt 0 ] \
	&& _max="%$_max" || _max=

    _dep=""; _job=""; _queue=""
    if [ -n "$3" ]; then _dep="-d afterany:$3"; fi	# dependencies

    if [ -n "$task_qname" ]; then _queue="-p $task_qname"; fi
    shift 4				# remaining args flow-through

	# Submit (sbatch) SLURM job of name $task_name
	# (task_qargs_QSYS set by the caller, below)


    # _log='run.log/%A_%a'
    _log="${_log_dir}/${_ppfx}T%a"
    echo sbatch -o "'$_log.out'" -e "'$_log.err'" \
	--parsable -J "$task_name" -a $_tlist$_max $_queue $_dep $_res \
	$task_qargs_QSYS --export=ALL "$task_sh" -name "$task_name" "$@"

    if $task_test; then
	eval "$_var"="${_var#J*}"	# fake job id
    else
	_job="$(sbatch -o "$_log.out" -e "$_log.err" \
	    --parsable -J "$task_name" -a $_tlist$_max $_queue $_dep $_res \
	    $task_qargs_QSYS --export=ALL "$task_sh" -name "$task_name" "$@")"
	# eval "$_var"="${_job%%;*}"	# save the job id
	_job="${_job%%;*}"		# remove cluster name
	eval "$_var"="$_job"		# save the job id
	_x=".${_ppfx}${_var}_${_job}"	# record submission
	touch "${_log_sdir:?}/$_x" "${_log_last:?}/$_x"
    fi
    return 0
}

# _sge submits (qsub) to SGE a new task w/ given dependencies, $3(%$2),
# and resources, $4, and stores the job id in "$1".
# Note that sge only supports tasks lists of the form a-b (+skip)

_sge () {
    local _var _tlist _log _dep _job _res _queue _max
    _chk_dir 'E_sge'

    _dep=""; _job=""; _queue=""
    _var="$1"						# <num> (J<num>:=$_job)
    _max="${2##*%}"					# everything after "%"
    _tlist="${2%\%*}"					# everything before "%"
    _res="$4"						# sge job params

	# process maximum concurent jobs in array

    [ -n "$_max" ] && [ ! "$_max" = "$2" ] && [ $_max -gt 0 ] \
	&& _max="%$_max" || _max=

    if [ -n "$3" ]; then
	_dep=$(echo "$3" | tr ':' ',')			# dependencies
	_dep="-hold_jid $_dep "
    fi
    if [ -n "$task_qname" ]; then _queue="-q $task_qname"; fi
    shift 4				# remaining args flow-through

	# Make sure -pe is used only once
	# (task_qargs_QSYS set by the caller, below)

    _word=""
    _args=""
    _pe=""
    _in=false
    for _word in $_res $task_qargs_QSYS; do
	case $_word in
	-pe) _in=true; _pe="-pe";;	# reset and record
	-*) _in=false; _args="$_args $_word";;
	*)  if $_in; then _pe="$_pe $_word"
	    else	  _args="$_args $_word"
	    fi;;
	esac
    done
    _res="$_args $_pe"
    unset _word _args _pe _in

	# Submit (qsub) SGE job of name $task_name

    # _log='run.log/$JOB_ID_$TASK_ID'
    _log="${_log_dir}/${_ppfx}T"'$TASK_ID'
    echo qsub -o "'$_log.out'" -e "'$_log.err'" -S /bin/sh -terse \
	    -V -cwd -N "$task_name" -t $_tlist$_max $_queue $_dep $_res \
	    "'$task_sh'" -name "'$task_name'" "$@"

    if $task_test; then
	eval "$_var"="${_var#J*}"	# fake job id
    else
	_job=$(qsub -o "$_log.out" -e "$_log.err" -S /bin/sh -terse \
	    -V -cwd -N "$task_name" -t $_tlist$_max $_queue $_dep $_res \
	    "$task_sh" -name "$task_name" "$@")
	_job="${_job%%.*}"		# remove array size info
	eval "$_var"="$_job"		# save the job id
	_x=".${_ppfx}${_var}_${_job}"	# record submission
	touch "${_log_sdir:?}/$_x" "${_log_last:?}/$_x"
    fi
    return 0
}

# _lsf_rescale rescales LSF "rusage" params in $task_qargs_QSYS according to
#   the value of $LSF_UNIT_FOR_LIMITS on this LSF server.
# - When emitting LSF '-R "rusage[xxx=k1:yyy=k2:...]"' arg, MOE is expected to
#   emit k1,k2,... in units of KB and suffix each value with _MOE_LSF_UNIT,
#   e.g. '-R "rusage[xxx=k1_MOE_LSF_UNIT:...]"'.
# - _lsf_rescale replaces each occurence of "=xxx_MOE_LSF_UNIT" with "=yyy",
#   where yyy=$(( (kkk + task_lsf_scale - 1) / task_lsf_scale ))
# - $task_qargs_QSYS is reset with the calculated values (sans _MOE_LSF_UNIT)

_lsf_rescale () {
    local _x _maxn
    _x="$task_qargs_QSYS"

    [ -n "$_x" -a -z "${_x##*_MOE_LSF_UNIT*}" ] || return 0	# no subst
    [ -z "${task_lsf_scale-}" ] && task_lsf_scale="$(_get_lsf_scale)"

    _maxn=99				# safety: limit max #iters
    while [ -n "$_x" -a -z "${_x##*_MOE_LSF_UNIT*}" ]; do
	_maxn=$(( _maxn - 1 ))		# safety: error if too many iters
	[ "$_maxn" -gt '0' ] || \
	    _err 4 E_lsfx1 "LSF unit conversion: $task_qargs_QSYS"

	_x1="${_x%%_MOE_LSF_UNIT*}"	# '-R "rusage[mem=123'
	_x3="${_x#*_MOE_LSF_UNIT}"	# ']"'
	_x2="${_x1##*=}"		# '123'
	_x2=$(( (_x2 + task_lsf_scale - 1) / task_lsf_scale ))
	_x1="${_x1%=*}="		# '-R "rusage[mem='
	_x="$_x1$_x2$_x3"
    done
    task_qargs_QSYS="$_x"
}

# _lsf submits (bsub) to LSF a new task w/ given dependencies, $3(%$2),
# and resources, $4, and stores the job id in "$1".

_lsf () {
    local _var _tlist _log _argv _dep _job _res _queue _max _x _x1 _x2 _x3
    _chk_dir 'E_lsf'

    _dep=""; _job=""; _queue=""
    _var="$1"						# <num> (J<num>:=$_job)
    _max="${2##*%}"					# everything after "%"
    _tlist="${2%\%*}"					# everything before "%"
    _res="$4 "						# lsf job params

	# Process maximum concurent jobs in array
	# Set $_tlist to job's array specification.

    [ -n "$_max" ] && [ ! "$_max" = "$2" ] && [ $_max -gt 0 ] \
	&& _max="%$_max" || _max=

    [ -n "$_tlist" ] && _tlist="[${_tlist}]$_max"

	# Convert dependencies, $3, to LSF format.

    if [ -n "$3" ]; then		# make the dependency string
	_a=; _b=""
	_dep=$(echo "$3" | tr ':' ' ')	# space-separated dependecies
	for _b in $_dep; do		# for each dependency in the list
	   _a="${_a}ended($_b)&&"	# append "ended($_b)&&" per dependecy
	done
	_dep="-w ${_a%&&} "		# remove the last/trailing "&&"
	unset _a _b
    fi
    if [ -n "$task_qname" ]; then _queue="-q '$task_qname' "; fi
    shift 4				# remaining args flow-through

    _lsf_rescale			# safety (alredy done before submit)

	# Submit (bsub) LSF job of name $task_name
	# (task_qargs_QSYS set by the caller, below)

    # _log='run.log/%J_%I'
    _log="${_log_dir}/${_ppfx}T%I"
    _argv=$(printf "\'%s\' " "$@")	# don't split multi-word items in $@

    echo bsub -o "$_log.out" -e "$_log.err" \
	-J "${task_name}${_tlist}" \
	-env "all" $_queue$_dep$_res $task_qargs_QSYS \
	"/bin/sh '$task_sh' -name '$task_name' $_argv"
    echo "$_job"

    if $task_test; then
	eval "$_var"="${_var#J*}"	# fake job id
    else
	_job=$(
	    LSB_JOB_REPORT_MAIL=N \
	    bsub -o "$_log.out" -e "$_log.err" \
		-J "${task_name}${_tlist}" \
		-env "all" $_queue$_dep$_res $task_qargs_QSYS \
		"/bin/sh '$task_sh' -name '$task_name' $_argv"
	    )
	_job="$(_subs "$_job" "#*<" "%%>*")"
	eval "$_var"="$_job"		# save the job id
	_x=".${_ppfx}${_var}_${_job}"	# record submission
	touch "${_log_sdir:?}/$_x" "${_log_last:?}/$_x"
    fi
    return 0
}

# WARNING: Before submission, MUST "cd" INTO THE SCRIPT DIRECTORY (=job dir).
# After submission, $0 will NO LONGER be a reliable path to the jobdir.



# 1) SUBMIT: Submit the entire set of jobs for execution and exit normally.
# Note: $task_submit=true means an explicit -submit or an implicit SH submit
# (task_mode='ShXxx') or an implicit non-SH submit (task_mode='XxxImpSub')

if $task_submit; then		# init & submit

	# If remote submit, ssh to task_host using $_flow args.

    if [ -n "$task_host" ]; then
	$_taction && {				# testing
	    $_upEnsure && _upEnsure='Up' || _upEnsure=
	    echo "A_RmtSub${_upEnsure}_${task_qsys} $_flow";
	    exit 0;
	}

	    # If a subtask (of a compute task), pass the currect logdir params
	    # the new remote process with -rsubid

	if [ -n "${_log_sdir-}" ]; then
	    _x="${_log_sdir}/.P${task_pid-}"	# RSUBID
	    _flow="$_flow-rsubid \"$_x\" "
	    touch "${_log_sdir}/.${_ppfx}M_ssh" "${_log_last}/.${_ppfx}M_ssh"
	    _x="_${_ppfx}ivalxx_resub"
	    _ivalxx | tee "${_log_last}/${_x}" > "${_log_sdir}/${_x}"
	fi

	_set_rsh_fn E_rfn2		# set _rsh_fn to a valid remote file
	_ssh "$_rsh \"$_rsh_fn\" $_flow" -- "$@" && _ecode=0 || _ecode=1
	exit $_ecode		# This is an intentional exit, not E_unk
    fi

    if [ -z "${task_mode##Exe*}" ]; then :	# compute task: keep CWD
    elif [ -n "${task_sh##*/*}" ]; then :	# $0 is a tailname: keep CWD
    else					# "cd" to jobdir=parent of $0
	cd "${task_sh%/*}"			# parent of run.sh
	task_sh="${task_sh##*/}"		# tailname
    fi
    $_nameCwd && { task_name="$PWD"; task_name="${task_name##*/}"; }
    task_shost="$_hostname"				# submission host
    export task_shost	 # !!! for resubmit from moebatch on compute node

    task_sfn="$PWD/$task_shx"			# $0 of the submission task
    _ecode=0; _elabel=E_initSub			# subs.initSub start (if any)

    _ecode=;  _elabel=				# subs.initSub done

	# If SH and logmode!=1, do NOT use run.log directory.
	# (Otherwise, run.log _will_ be used.)
	# logmode=0: cat all stdout/err, logmode=2: use $PWD/T<num>.out/.err
	# WARNING: runs the job now, on this host; returns only when finished

    [ "$task_qsys" = 'sh' -a "$task_logmode" != 1 ] && {
	if [ -n "${task_mode##*Sh*}" ]; then		# SH non-submit mode
	    _err 4 E_runsh0 "Unexpected non-SH mode: $task_mode"
	elif [ -z "${task_mode##*Sub}" ]; then :	# requesting run.log
	    _err 4 E_runsh1 "Unexpected SH submit mode: $task_mode"
	fi
	[ -n "${task_mode##*Sh*}" ] && _err 4 E_runsh1 "Non-SH mode $task_mode"
	[ -z "${task_mode##*Sub}" ] && _err 4 E_runsh2 "Submit mode $task_mode"

	_log_id=; _log_dir=; _log_sdir=; _log_last=	# no run.log
	[ "$task_logmode" = 2 ] && _log_dir="$PWD"	# > $PWD/T<num>.out
	task_logdir="$PWD"		# usable by payload (if needed)
	$_taction && { echo "A_ShRun${task_logmode}"; exit 0; }	# testing
	_ecode=0; _elabel=E_shCalls	# subs.shCalls
	_seq "J1" "1-$task_parts" "" "" -parts "$task_parts" -- "$@"
	_seq "J2" "$((task_parts + 1))" "$J1" "" -parts "$task_parts" -- "$@"
	_ecode=0; _elabel=E_afterSub	# subs.afterSub (if any)

	_ecode=;	_elabel=	# ShRun done
	exit 0
    }

	# Set task_qargs_QSYS to all resources in QSYS=$task_qsys format

    task_qargs_QSYS=		# safety: do NOT default to non-empty!
    eval task_qargx_QSYS='"${task_qargx_'$task_qsys'-}"'
    task_qargx_QSYS="${task_qargx:-$task_qargx_QSYS}"
    eval task_qargs_QSYS='"${task_qargs_'$task_qsys'-}"'
    task_qargs_QSYS="${task_qargs:-$task_qargs_QSYS}"
    task_qargs_QSYS="$task_qargs_QSYS $task_qargx_QSYS"
    $_taction && { echo "A_Sub_$task_qsys"; exit 0; }	# testing

	# If task_logdir undefined, then this is a new main job (not a subjob).
	# Note: $task_logdir is the destination of stdout/stderr files, usable
	# by the payload code. (The preamble uses $_log_dir instead.)

    if [ -z "${task_mode##*Sub}" ]; then :		# OK: submit mode
    elif [ -n "${task_mode##*Sh*}" ]; then		# SH non-submit mode
	_err 4 E_subx_0B "Unexpected SH run mode: $task_mode"	# no run.log
    else
	_err 4 E_subx_1B "Unexpected task mode: $task_mode" 	# safety
    fi

    if [ -z "${_log_sdir-}" ]; then			# new submission
	_x="$PWD/run.log"				# ensure run.log
	mkdir -p "$_x" >&2	  || _err 3 E_sub_1 "can't create $_x"

	_log_last="$_x/.jlast"				# empty run.log/.jlast
	rm -rf "${_log_last:?}"				# del last run info
	mkdir -p "$_log_last" >&2 || _err 3 E_sub_2 "can't create $_log_last"

	_log_id="$(date +%Y_%m%d_%H%M_%S%N)"		# nanoseconds
	_log_id="${_log_id%??????}_${task_qsys:=sh}"	# milliseconds+qsys
	[ -n "${_log_id##20*}" ]  && _err 3 E_sub_3 "Bad _log_id $_log_id"

	_log_dir="$_x/$_log_id"				# logdir for this job
	task_pid=					# empty=a primary task

	mkdir -p "$_log_dir" >&2  || _err 3 E_sub_4 "can't create $_log_dir"

	_log_sdir="$_log_dir"'/.jstate'			# state markers
	mkdir -p "$_log_sdir" >&2 || _err 3 E_sub_5 "can't create $_log_sdir"

	task_logdir="$_log_dir"		# destination of stdout/stderr files

	# If task_logdir _is_ defined, then this is a subjob:
	# - validate logdir subdirs, e.g. "$_log_sdir"
	# - create a marker prefix, .e.g. ".P0.1."
	# - prefix all marker files with that prefix, e.g. ".P0.1.T0_ok"

    else						# subtask/resubmission
	_validate_log_dir 'E_resub'			# validate subdirs
	if [ -n "${task_id-}" ];	then :		# parent's task_id
	elif [ -n "${_qtask_id-}" ];	then task_id="$_qtask_id" # from QSYS
	elif [ -n "${_rsubid-}" ];	then task_id=0	# ssh + resubmit
	elif [ "$task_mode" = 'ShSub' ]; then task_id=0	# stage-2 on SH queue
	else				_err 3 E_resub_t0 '$task_id not set'
	fi
    fi

	# On LSF, resources have to be rescaled using LSF_UNIT_FOR_LIMITS

    [ "$task_qsys" = "lsf"   ]	&& _lsf_rescale		# "-R rusage[...]"

	# Ensure logsubdirs, job markers.

    _x=".${_ppfx}JN_${task_JN:?}"			# record no.submissions
    touch "${_log_sdir:?}/$_x" "${_log_last:?}/$_x"

    printf '%s' "$_log_id" > "$_log_last"'/_log_id'	# record curr.logdir
    _log_id2=$(cat "$PWD/run.log/.jlast/_log_id")	# read back & cmp
    [ "$_log_id" = "$_log_id2" ] || \
	_err 3 E_logfail_4 "_log_id failed: .$_log_id. != .$_log_id2.\n"
    touch "$_log_last"'/.log_id_'"$_log_id"			# logdir as sfx

    _x=".${_ppfx}TX_init"
    touch "${_log_sdir}/${_x}" "${_log_last}/${_x}"	# init state

    _x="_${_ppfx}ivalx"
    _ivalx | tee "${_log_last}/${_x}" > "${_log_sdir}/${_x}"	# -ivalx info
    _x="_${_ppfx}ivalxx"
    _ivalxx | tee "${_log_last}/${_x}" > "${_log_sdir}/${_x}"	# -ivalxx diag
    _x="_${_ppfx}task_qid"
    printf '%s' "$task_qid" | \
	tee "$_log_last/$_x" > "$_log_sdir/$_x"		# hpc.cfg qid
    _x="${_ppfx}.task_qid_$task_qid"
    [ -n "${task_qid##*[^a-zA-Z0-9_-=.]*}" ] && \
	touch "$_log_sdir/$_x" "$_log_last/$_x"		# qid as sfx

	# Set ".T0_unk" marker to indicate job submission.  If job finishes
	# with success/failure, ".T0_unk" will be replaced with ".T0_ok"/".T_err".

    [ -z "${_ppfx}" ] && {	# tmp. fix: don't use T0_unk if a subtask
	_x=".${_ppfx}T0_unk"
	touch "$_log_sdir/$_x" "$_log_last/$_x"	 # replaced by T0_ok/T0_err
    }

	# Submit to the given qsys.  IMPORTANT: all post-"--" cmd.line args
	# will be given to each submitted jobs as as their cmd.line args
	# AFTER an explicit "--". (See COMMAND_LINE above)
	# Each jobs will also receive the full environment of this process.

    _after "2" "1"
    _ecode=0; _elabel="E_${task_qsys-}Calls"	# subs.xxxCalls
    if   [ "$task_qsys" = "sge"   ]; then :
	_sge "J1" "1-$task_parts" "" "" -parts "$task_parts" -- "$@"
	_sge "J2" "$((task_parts + 1))" "$J1" "" -parts "$task_parts" -- "$@"
    elif [ "$task_qsys" = "slurm" ]; then :
	_slurm "J1" "1-$task_parts" "" "" -parts "$task_parts" -- "$@"
	_slurm "J2" "$((task_parts + 1))" "$J1" "" -parts "$task_parts" -- "$@"
    elif [ "$task_qsys" = "lsf"   ]; then :
	_lsf "J1" "1-$task_parts" "" "" -parts "$task_parts" -- "$@"
	_lsf "J2" "$((task_parts + 1))" "$J1" "" -parts "$task_parts" -- "$@"
    elif [ "$task_qsys" = "sh"    ]; then :
	# Since "sh" is run immediately, the state already _is_ "submitted".
    else
	_err 4 E_que1B "Unsupported value: -qsys $task_qsys (sh|slurm|sge|lsf)"
    fi
    _ecode=; _elabel=				# subs.xxxCalls done

	# Replace .TX_submit with .TX_init. Set TN_#, TN0_#.

    _x=".${_ppfx}TX_submit"
    touch "$_log_sdir/${_x}" "${_log_last}/${_x}"		# job submitted
    _x=".${_ppfx}TX_init"
    rm -rf "${_log_sdir:?}/${_x}" "${_log_last:-.}/${_x}"	# init finished

    _x=".${_ppfx}TN_"
    touch "$_log_sdir/${_x}${task_N}"				# #tasks
    rm -f "${_log_last:?}/${_x}"* 2>/dev/null			# safety
    touch "$_log_last/${_x}${task_N}"

    _x=".${_ppfx}TN0_"
    touch "$_log_sdir/${_x}${task_N0}"				# #tasks
    rm -f "${_log_last:?}/${_x}"* 2>/dev/null			# safety
    touch "$_log_last/${_x}${task_N0}"

	# If "sh", treat as "submitted" and run immediately.

    if [ "$task_qsys" = "sh"    ]; then :
	# WARNING: runs the job now, on this host; returns only when finished
	_ecode=0; _elabel=E_shCalls	# subs.shCalls

	_seq "J1" "1-$task_parts" "" "" -parts "$task_parts" -- "$@"
	_seq "J2" "$((task_parts + 1))" "$J1" "" -parts "$task_parts" -- "$@"
    fi

    _ecode=0; _elabel=E_afterSub	# subs.afterSub (if any)

    _ecode=;  _elabel=			# Sub done
    exit 0				# init done: submitted

# 2) START: Expected task mode 'Exe' or 'ExeSh'. Verify _log_xxx vars etc.
# Note: If 'ExeSh' and task_logmode!=1, run.log will not be used.
# - $_log_id!='' indicates that run.log WILL be used; (if SH, task_logmode=1)
# - if SH, task_logmode == ($_log_id!='' ? 1 : $_log_dir='' ? 0 : 2)

else
    if [ "$task_mode" != 'ExeSh' ]; then
	[ "$task_mode" != 'Exe' ] && _err 3 E_badexe_1 'Unexpected task state'
	[ -z "${_log_sdir-}" ]	  && _err 3 E_badexe_2 'Unexpected non-SH task'
    fi

    $_taction && { echo 'A_Exe_runlog'; exit 0; }	# testing

    [ -z "${task_logdir-}" ]	&& _err 3 E_badexe_3 'task_logdir not set'
    [ ! -d "$task_logdir" ] && _err 3 E_badexe_4 "$task_logdir not a directory"
fi

# 2a) START_SUB: Use run.log. Validate _log_xxx vars and log subdirs.

if [ -n "${_log_sdir-}" ]; then
    _validate_log_dir 'E_rlog'				# validate subdirs
    [ -z "${task_id-}" ]	&& _err 3 E_rlog_t0 '$task_id not set'
    _after_verify "$task_id"	#  exit 1 if ".E_${task_id}" exists

    _x=".${_ppfx}T${task_id}_start"
    touch "$_log_sdir/$_x" "$_log_last/$_x"

# 2b) START_SHRUN: Do NOT use run.log; stdout,stderr NOT redirected to run.log.
# _log_dir non-empty means stdout,stderr sent to a file, jobdir/T<n>.out,err

else
    [ -n "${_log_dir-}" ] && [ "$_log_dir" != "$task_logdir" ] \
				&& _err 3 E_rlog_s1 '_log_dir != task_logdir'
    _log_last=					# safety
    task_sfn="${task_sfn:-$PWD/$task_shx}"
fi

# Unset local variables except for those that are meant to be used in
# the rest of the script: task_N, task_parts, task_max and task_id
# Note: task_logdir (a subset of run.log) is the destination of stdout
# of the current run.  sh SH seq jobs

_unset_vars

# === STEP_6: ===============================================================
# RESVARS: Set vars used by the payload preamble, e.g. moe_u.sh

# Ensure correct setting of $task_qsys

if   [ -n "${SLURM_ARRAY_TASK_ID-}" ]; then	task_qsys="slurm"
elif [ -n "${SGE_TASK_ID-}"         ]; then	task_qsys="sge"
elif [ -n "${LSB_JOBINDEX-}"        ]; then	task_qsys="lsf"
else						task_qsys="sh"
fi

# Verify that ExeSh* modes are SH submissions, while other Exe* are non-SH.

_mode_ok=false
case "$task_mode" in
    ExeSh* )	[ "$task_qsys" = 'sh' ] && _mode_ok=true;;
    Exe* )	[ "$task_qsys" = 'sh' ] || _mode_ok=true;;
esac
$_mode_ok || _err 4 E_exe3B "Unexpected mode=$task_mode qsys=$task_qsys"

# Set up job resource variables, to be used by payload preamble, e.g. moe_u.sh.
# task_cpu	: number of shared-memory cpus per node
# task_mem	: MB of available memory per node
# task_nodes	: number of available nodes

task_cpu=; task_mem=0; task_nodes=

if   [ "$task_qsys" = 'sge'   ]; then
    _hostnodes='1'		# number of nodes on the host machine
    if [ -f "${PE_HOSTFILE-}" ]; then
	_hostnodes="$(awk -v host="$(hostname)" \
	    '{if($1==host){n+=$2}}END{print n}' "$PE_HOSTFILE")"
	if [ "$_hostnodes" = '0' ]; then _hostnodes=1; fi
    fi

    task_mem="$(ulimit -d)"	# mem in KB * number of nodes on this machine
    [ "$task_mem" = 'unlimited' ] && task_mem=0
    task_mem="$(( $task_mem / $_hostnodes / 1024))" # mem in MB per node

	# !!! 1xn and nx1 are indistinguishable using NHOSTS and NSLOTS only.

    NSLOTS=${NSLOTS:-1}
    NHOSTS=${NHOSTS:-1}
    if [ "$NHOSTS" -eq 1 ]; then
	task_cpu=$NSLOTS; task_nodes=1
    else
	task_cpu=1;	  task_nodes=$NSLOTS
    fi
    unset _hostnodes

elif [ "$task_qsys" = 'slurm' ]; then
    task_cpu="${SLURM_CPUS_PER_TASK:-1}"		# shared cpus per node
    task_nodes="${SLURM_NPROCS:-1}"
    task_nodes="${SLURM_NTASKS:-$task_nodes}"

    _per_cpu=false
    if   [ -n "${SLURM_MEM_PER_NODE-}" ]; then
	task_mem="$SLURM_MEM_PER_NODE"
    elif [ -n "${SLURM_MEM_PER_CPU-}" ]; then
	task_mem="$SLURM_MEM_PER_CPU"
	_per_cpu=true
    fi
    task_mem="$(_read_mem "$task_mem" 'MB')"
    $_per_cpu && task_mem="$((task_mem * task_cpu))"	# mem per node in MB

    unset _per_cpu

elif [ "$task_qsys" = 'lsf'   ]; then
    task_cpu="${LSB_SUB_RES_REQ-}"
    task_cpu="$(_subs "$task_cpu" "#*affinity[" "#*core(" "%%)*" "%%,*")"
    if [ "$task_cpu" = "${LSB_SUB_RES_REQ-}" ]; then
	task_cpu=1
    fi

    task_nodes=1
    if [ -n "${LSB_MCPU_HOSTS-}" ]; then
	task_nodes="$(echo "$LSB_MCPU_HOSTS" \
	    | awk 'BEGIN{sum=0}{sum=sum+$2}END{print sum}')"
    fi

    _default="$(_get_lsf_unit)"				# $LSF_UNIT_FOR_LIMITS
    task_mem="$(_subs "${LSB_SUB_RES_REQ-}" "#*mem=" "%%:*" "%%]*" "%%,*")"
    if [ "$task_mem" = "${LSB_SUB_RES_REQ-}" ]; then
	task_mem=0
    fi
    task_mem="$(_read_mem "$task_mem" "$_default")"

    unset _default

elif [ "$task_qsys" = 'sh'    ] || [ -n "$task_qsys" ]; then
    true

else
    task_nodes="${task_nodes=1}"
    _err 4 E_que2B "Unsupported value: -qsys ${task_qsys-} (sh|slurm|sge|lsf)"
fi

# === STEP_7: Payload =======================================================
# Note: The current directory is where this script resides.
# task_id is now set to {1,...,N} for tasks and 0 for cleanup
# (where N = task_N is the total number of tasks
# "$@" contains all CLI flags given after --

set +u			# below, do NOT complain about unset vars
_ecode=0		# preamble finished (payload follows)
_elabel=E_runConfig	# subs.runConfig (if any)
task_lastid="${task_id-}"
# ===========================================================================
# PAYLOAD CONFIG:



# ===========================================================================
_elabel=E_run		# subs.runConfig (if any) & payload
# ===========================================================================
# PAYLOAD:





# Set MOE if not already set

if [ -z "${MOE-}" ]; then :
#   [1] insert code to set MOE here
fi

# Look in the PATH for a valid moebatch executable

if [ -z "${MOE-}" ]; then
    if command -v moebatch 1>/dev/null 2>&1; then # moebatch is on the path
	MOE="$(command -v moebatch)"
	MOE="${MOE%/*}"		# remove the trailing /moe
	MOE="${MOE%/*}"		# remove the trailing /bin
	if ! test -d "$MOE/bin" -a -d "$MOE/lib" -a -d "$MOE/svl"; then
	    MOE=""	# the folder is invalid
	fi
    fi
fi

# Validate the current MOE variable
# Note: Ensure that MOE_ERRFCN _is_ defined & reports error to stderr.
# This function _will_ be defined in run.sh emitted by hpc_Script.

if [ -z "${MOE-}" ]; then
    command -v MOE_ERRFCN 1>/dev/null 2>&1 || MOE_ERRFCN () {
	printf '%s: %s [%s]\n' "${0##*/}" "${3-}" "${2-}" >&2
	exit "${1-2}"
    }

    MOE_ERRFCN 2 E_moe1 'MOE environment variable not set'
fi

# MOEBATCH will create a machine file if appropriate, make a moebatch call and
# then remove the machine file.
# Warning: assumes $MOE is set & validated by moe_init.sh
# Usage:  MOEBATCH -run "$0"	... "$0" is typically a copy of run.sh
# Safety: exit "$?"		... an extra line, not expected to execute

MOEBATCH () {
    [ -z "${MOE-}" ] && { echo '$MOE undefined' >&2; exit 4; }	# 4=coding bug
    local _noexit _arg _ok _mpu _mpu_N

    [ "${1-}" = '--noexit' ] && { _noexit=true; shift; } || _noexit=false

	# Set arguments for moebatch.  Note: $task_cpu should be set by the
	# caller to the #threads usable (=#cores available to each mpu host)

    _nthreads="${task_cpu-}"
    [ "$_nthreads" -eq "$_nthreads" ] 2>/dev/null || _nthreads=	# not a number
    [ -n "$_nthreads" ] && _nthreads="-maxthreads $_nthreads"
    _arg="-stdc -errexit 1 -notty $_nthreads"

	# _moe_addxxx are set by run.sh when -addxxx cmd.line arg are used.

    [ -n "${_moe_addpatch-}" ]	&& set -- -addpatch "$_moe_addpatch" "$@"
    [ -n "${_moe_addcustom-}" ]	&& set -- -addcustom "$_moe_addcustom" "$@"

	# If SH, run moebatch now (without run.log)

	# !!! use the value logmode!
	# in run.sh, set logmode (after _ivalx is called) according to
	# whether or not run.log is meant to be used by SH

    task_mpu="run.log/${task_id:-x}.mpu"
    case "${task_qsys-}" in
	slurm)
	    [ -z "${SLURM_NTASKS-}" ]	&& task_mpu=	;;
	sge)
	    [ -z "${NSLOTS-}" ]		&& task_mpu=	;;
	lsf)
	    [ -z "${LSB_MCPU_HOSTS-}" ] && task_mpu=	;;
	*)
	    task_mpu=	# safety
	    "$MOE/bin/moebatch" $_arg "$@" && return 0
	    $_noexit && return 1 || exit 1		;;
    esac

	# The machine files are placed in the log directory and deleted if
	# the task completes successfully.

    mkdir -p 'run.log'				# ensure logdir

	# Read the allocated work node resources and create a machine file.

    _ssh_opts=" -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
    _moe_mpu="'\$MOE/bin/moebatch -mpu -'"

    if   [ -z "$task_mpu" ]; then :
    elif   [ "$task_qsys" = "lsf" ]; then
	echo "${LSB_MCPU_HOSTS-}" | \
	awk -v opt="$_ssh_opts" -v moe="$_moe_mpu" \
	'{for (i=0;i<$2;i++) {
	    printf "localhost ssh%s %s %s\n", opt, $1, moe
	}}' > "$task_mpu"

	# PE_HOSTFILE: each line defines one host:
	#   hostname #processes que.name processor_range(if multiproc.machine)
	# awk line arg: $1=host name $2=host count

    elif [ "$task_qsys" = "sge" ]; then
	awk -v host="$(hostname)" -v opt="$_ssh_opts" -v moe="$_moe_mpu" \
	'BEGIN {printf "localhost ssh%s %s %s\n", opt, host, moe}
	{for (i=0;i<$2-($1==host);i++) {
	    printf "localhost ssh%s %s %s\n", opt, $1, moe
	}}' $PE_HOSTFILE > "$task_mpu"

	# srun hostname: each line lists hostname of one task (lines repeated)



    elif [ "$task_qsys" = "slurm" ]; then
	srun /bin/hostname | sort | \
	awk -v opt="$_ssh_opts" -v moe="$_moe_mpu" \
	'{printf "localhost ssh%s %s %s\n", opt, $1, moe}' \
	> "$task_mpu"

    else
	echo "" > "$task_mpu"	# clean a leftover task_mpu file, if any
    fi
    unset _ssh_opts _moe_mpu

	# Only keep the machine file if it has more than one node.

    _mpu_N=1
    [ -f "$task_mpu" ] && _mpu_N="$(awk 'END{print NR}' "$task_mpu")"

    if [ "$_mpu_N" -gt 1 ]; then
	_mpu='-mpu'
	echo '$eof' >> "$task_mpu"
    else
	[ -f "$task_mpu" ] && rm -f "$task_mpu"
	_mpu=
	task_mpu=		# empty CLI arg
    fi

	# Execute the moebatch call with the appropriate machine file.
	# Clean the machine file if it was created.

    _ok=true
    "$MOE/bin/moebatch" $_arg "$_mpu" "$task_mpu" "$@" || _ok=false
    [ -n "$task_mpu" -a -f "$task_mpu" ] && rm -f "$task_mpu"

    $_ok && return 0

    [ -n "${_mpu:-}" ] && _mpu="-mpu $_mpu_N"
    echo "FAILED: moebatch $_arg $_mpu" "$@" >&2
    $_noexit && return 1 || exit 1
}

MOEBATCH -run "$0" -parts "$task_parts" -task_i "$task_id" "$@" -exit
exit 0
#endif

#svl
//	This is SVL source code that has been machine-generated by MOE.
//	DO NOT MODIFY BY HAND
//
//	File: run.sh
//	Date: Tue Jun 15 12:36:09 2021
//	Creator: Docking in MOE (2020.09)
//
// LICENSE:
//
// COPYRIGHT (C) 2020 CHEMICAL COMPUTING GROUP ULC ("CCG").
// ALL RIGHTS RESERVED.
//
// ACCESS TO AND USE OF THIS SOFTWARE IS GOVERNED BY A SOFTWARE LICENSE
// AGREEMENT WITH CCG OR AN AUTHORIZED DISTRIBUTOR OF CCG.
//
// PERMISSION TO USE, COPY, MODIFY AND DISTRIBUTE THIS SOFTWARE IS HEREBY
// GRANTED PROVIDED THAT: (1) UNMODIFIED OR FUNCTIONALLY EQUIVALENT SOFTWARE
// DERIVED FROM THIS SOFTWARE MUST CONTAIN THIS NOTICE; (2) ALL CODE DERIVED
// FROM THIS SOFTWARE MUST ACKNOWLEDGE THE AUTHOR(S) AND INSTITUTION(S); (3)
// THE NAMES OF THE AUTHOR(S) AND INSTITUTION(S) NOT BE USED IN ADVERTISING
// OR PUBLICITY PERTAINING TO THIS SOFTWARE WITHOUT SPECIFIC WRITTEN PRIOR
// PERMISSION; (4) ALL CODE DERIVED FROM THIS SOFTWARE BE EXECUTED WITH THE
// MOLECULAR OPERATING ENVIRONMENT LICENSED FROM CCG.
//
// CCG DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING
// ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, AND IN NO EVENT
// SHALL CCG BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR
// ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER
// IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
// OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
// INPUT FILES:
//
// rec: rec.moe
// lig: lig.moe
//
// OUTPUT FILES:
//
// output: example_dock.mdb
//
// USAGE:
//    In a terminal shell (Unix) or in a Command Prompt (Windows):
//    moebatch -run run.sh
//    
//         -rec  file : Point to a receptor file
//         -site file : Define a different site expression
//         -lig  file : Point to a ligand file
//         -ph4  file : Point to a pharmacophore filter file
//         -o    file : Rename the output mdb where the docked poses are saved
//         -ed   file : Point to a pharmacophore filter file
//         -resume    : Tries to resume calculation from any existing output files
//         -force     : Overwrites any existing output. When used in combination
//    		  with -resume any output file that cannot be resumed from
//    		  will be overwritten without a prompt
//         -mpu N     : Perform the docking in parallel moebatch instances
//         -nthreads N: Number of CPU threads used by forcefield calculations
//         -parts N   : Partition a task into N independent tasks
//         -task_i i  : Run a specific task #. Task 0 is the post-processing task
//    		  that produces the final results database
//    
//        The following are example use scenarios:
//    
//    	moebatch -run run.sh -o newname.mdb
//    	moebatch -run run.sh -mpu #
//    	moebatch -run run.sh -mpu # -nthreads 1
//    
//    The shell script can be used to submit to HPC. Type sh run.sh -help for help
//    
//        sh run.sh -submit      # use all the settings defined at batch creation
//    
//        sh run.sh -qsys slurm -host head:./dir -parts 128 -upload -submit
//        sh run.sh -qsys slurm -host head:./dir -parts 128 -submit -- -resume

global argv;
function ArgvPull, Dock, edens_sf_Read;

local function main opt_override
    ArgvReset ArgvExpand argv;
    local [_recfn, _ligfn] = ArgvPull [['-rec','-lig'],  1];
    local [_site, _ph4fn]  = ArgvPull [['-site', '-ph4'],  1];
    local [task_i, _outfn] = ArgvPull [['-task_i', '-o'], 1];
    local [task_parts]	   = ArgvPull [['-parts'], 1];
    local [_jobdir]	   = ArgvPull [['-jobdir'],  1];

    local rec		= [
	atom_sel: '$MOEDock_Rec',
	file: 'rec.moe',
	copy: 0,
	sel_only: 0,
	type: 'MOE File',
	mfield: '',
	site_sel: '$MOEDock_Site'
    ];
    local lig		= [
	atom_sel: '$MOEDock_Lig',
	file: 'lig.moe',
	copy: 0,
	sel_only: 0,
	copy_fields: 1,
	mfield: '',
	Efield: '',
	type: 'MOE File'
    ];
    local site		= '';
    local ph4fn		= '';
    local outfn		= 'example_dock.mdb';
    local nthreads	= [];

    local jobdir = fparent (modenv []).filename;

	// Gather the CLI arguments.

    if notnull _ligfn  then lig		= _ligfn;   endif
    if notnull _recfn  then rec		= _recfn;   endif
    if notnull _ph4fn  then ph4fn	= _ph4fn;   endif
    if notnull _outfn  then outfn	= _outfn;   endif
    if notnull _jobdir then jobdir	= _jobdir;  endif
    if notnull _site   then site	= _site;    endif
    local opt	= [
	wall: ['',0,[0,0,0],[1000000,1000000,1000000],0],
	csearch: 1,
	confGenMethod: 'Rotate Bonds',
	ignoreMseq: 0,
	dockmode: 'General',
	placement: 'Triangle Matcher',
	placement_opt: [
	    timeout: 300,
	    nretpose: 1000,
	    mode: 'General',
	    silent: 0
	],
	scoring: 'London dG',
	dup_placement: 1,
	maxpose: 400,
	refine: 'Rigid Receptor',
	refine_opt: [
	    fixrec: 'Fix',
	    ed_map: 'Fo',
	    ed_f: 'Simulated',
	    ed_phi: 'Simulated',
	    ed_f2: 'Simulated',
	    ed_path: '',
	    ed_res: 2.5000,
	    ed_surflevelD: 3,
	    cutoff: 6,
	    wholeres: 1,
	    mmgbvi: 1,
	    packsidechains: 1,
	    rigidlig: 0,
	    rigidPlanar: 0,
	    tether: 10,
	    gtest: 0.0100,
	    maxit: 500,
	    OverrideSetup: 1,
	    k_potl: 100,
	    roffset: 0.4000,
	    silent: 0
	],
	rescoring: 'GBVI/WSA dG',
	dup_refine: 1,
	remaxpose: 5,
	descexpr: '',
	rxnFile: '',
	rxnimponly: 0,
	edsupport: 1,
	multiLigand: 1,
	need_dmat: 1,
	gen_plif: 1,
	tempDB: 1,
	opendbv: 1,
	task_parts: 1,
	rxsite: 'pocket and not inert',
	run_mode: 'run',
	hpc_opt: [
	    title: 
		'E:/onedrive - the university of memphis/guides/ligand_docking'
		'_tutorial_files/example_dock',
	    jhash: 'r9m9a8'
	],
	create_mdb: 0,
	embed3d: 0,
	sel_ent_only: 0,
	sel_ent_only_rec: 0,
	retainData: 1,
	ph4loosen: 0.5000,
	dock_results: 'full',
	result_count: 0,
	out_rmsd: 1,
	result_sum: 0,
	add_mseq: 0,
	verbose: 1,
	silent: 0,
	randseed: 3931055,
	placement_fcn: 'dock_place_DistMatcher',
	scoring_fcn: 'dock_score_London_dG',
	scoring_opt: [
	    silent: 0
	],
	refine_fcn: 'dock_refine_ForcefieldFixed',
	rescoring_fcn: 'dock_score_GBVIWSA_dG',
	rescoring_opt: [
	    silent: 0
	],
	recSpec: 'MOE File',
	receptor_mfield: '',
	rec_sel: '$MOEDock_Rec',
	recfile: 'rec.moe',
	recfile_copy: 0,
	ligSpec: 'MOE File',
	ligand_mfield: '',
	ligand_Efield: '',
	Efield: '',
	lig_sel: '$MOEDock_Lig',
	ligfile: 'lig.moe',
	ligfile_copy: 0,
	ph4: []
    ];
    opt.BatchFile	= 'run.sh';
    opt.force	= ArgvPull ['-force',  0];
    opt.resume	= ArgvPull ['-resume', 0];

    opt		= tagcat [opt_override, opt];	// function call options

    if notnull task_i	then opt.task_i	    = tonum task_i; endif
    if notnull task_parts	then opt.task_parts = tonum task_parts; endif

    if isnull opt.task_i and opt.task_parts > 1 then
	exit 'Specify a -task_i value';
    endif

	// PH4 file.

    if 'file' == ftype ph4fn then opt.ph4 = ph4fn; endif

	// Restore electron density grid data.

    local f = 'ed_map.svl';
    if 'file' == ftype f then
	opt.edata = freadb [f, 'SVL'];
    endif

	// Restore electron density data.

    f = 'ed.mtz';
    if 'file' == ftype f and isnull opt.ed_data.ed_sfdata then
	opt.ed_data.ed_sfdata = task_call ['edens_sf_Read', f];
    endif

	// The following is the general potential set up only.
	// Individual stages like refinement may use a modified set up.

    pot_Load '$MOE/lib/Amber10EHT.ff.gz';
    pot_Setup [
	strEnable: 1,
	angEnable: 1,
	stbEnable: 1,
	oopEnable: 1,
	torEnable: 1,
	vdwEnable: 1,
	eleEnable: 1,
	solEnable: 0,
	resEnable: 1,
	strWeight: 1,
	angWeight: 1,
	stbWeight: 1,
	oopWeight: 1,
	torWeight: 1,
	vdwWeight: 1,
	eleWeight: 1,
	solWeight: 1,
	resWeight: 1,
	cutoffEnable: 1,
	cutoffOn: 8,
	cutoffOff: 10,
	eleDist: 2,
	vdwScale14: 0.5000,
	vdwBuffer1: 0,
	vdwBuffer2: 0,
	eleScale14: 0.83333333330000003,
	eleDielectric: 1,
	eleBuffer: 0,
	solDielectric: 80,
	solDielectricOffset: 0,
	state0: 1,
	state1: 0,
	state2: 1,
	threadCount: 0
    ];

	// Dock launch.

    Dock [rec, site, lig, outfn, opt];
endfunction
#eof
